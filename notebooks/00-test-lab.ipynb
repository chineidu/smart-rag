{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7cad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import warnings\n",
    "from typing import Any, Literal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"white\": \"#FFFFFF\",  # Bright white\n",
    "        \"info\": \"#00FF00\",  # Bright green\n",
    "        \"warning\": \"#FFD700\",  # Bright gold\n",
    "        \"error\": \"#FF1493\",  # Deep pink\n",
    "        \"success\": \"#00FFFF\",  # Cyan\n",
    "        \"highlight\": \"#FF4500\",  # Orange-red\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# NumPy settings\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Polars settings\n",
    "pl.Config.set_fmt_str_lengths(1_000)\n",
    "pl.Config.set_tbl_cols(n=1_000)\n",
    "pl.Config.set_tbl_rows(n=200)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba7e078f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Smart-RAG', 'version': '1.0'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def go_up_from_current_directory(*, go_up: int = 1) -> None:\n",
    "    \"\"\"This is used to up a number of directories.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    go_up: int, default=1\n",
    "        This indicates the number of times to go back up from the current directory.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    import os\n",
    "\n",
    "    CONST: str = \"../\"\n",
    "    NUM: str = CONST * go_up\n",
    "\n",
    "    # Goto the previous directory\n",
    "    prev_directory = os.path.join(os.path.dirname(__name__), NUM)\n",
    "    # Get the 'absolute path' of the previous directory\n",
    "    abs_path_prev_directory = os.path.abspath(prev_directory)\n",
    "\n",
    "    # Add the path to the System paths\n",
    "    sys.path.insert(0, abs_path_prev_directory)\n",
    "    print(abs_path_prev_directory)\n",
    "\n",
    "\n",
    "# Demo (Prevents ruff from removing the unused module import)\n",
    "name: Any\n",
    "category: Literal[\"A\", \"B\", \"C\"]\n",
    "json.loads('{\"name\": \"Smart-RAG\", \"version\": \"1.0\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da164420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mac/Desktop/Projects/smart-rag\n"
     ]
    }
   ],
   "source": [
    "go_up_from_current_directory(go_up=1)\n",
    "\n",
    "from src.config import app_settings  # noqa: E402\n",
    "from src.utilities.model_config import RemoteModel  # noqa: E402\n",
    "\n",
    "settings = app_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec396d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "527e9ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "remote_llm = ChatOpenAI(\n",
    "    api_key=settings.OPENROUTER_API_KEY.get_secret_value(),  # type: ignore\n",
    "    base_url=settings.OPENROUTER_URL,\n",
    "    temperature=0.0,\n",
    "    model=RemoteModel.GEMINI_2_0_FLASH_001,\n",
    ")\n",
    "\n",
    "\n",
    "# Test the LLMs\n",
    "response = remote_llm.invoke(\"Tell me a very short joke.\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593ca6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c54bd3",
   "metadata": {},
   "source": [
    "#### Create Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24c9f632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is agentic RAG?',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.ibm.com/think/topics/agentic-rag',\n",
       "   'title': 'What is Agentic RAG? | IBM',\n",
       "   'content': '# What is agentic RAG? Agentic RAG is the use of AI agents to facilitate retrieval augmented generation (RAG). Agentic RAG systems add AI agents to the RAG pipeline to increase adaptability and accuracy. Compared to traditional RAG systems, agentic RAG allows large language models (LLMs) to conduct information retrieval from multiple sources and handle more complex workflows. ### What is agentic AI? AI agents ### What are AI agents? ## How does agentic RAG work? Agentic RAG works by incorporating one or more types of AI agents into RAG systems. Agentic RAG systems can contain one or more types of AI agents, such as: Report   Agentic AI products to watch out for in 2025  AI agents for business    IBM AI agent solutions    Explore AI agent solutions   ',\n",
       "   'score': 0.9484276,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.glean.com/blog/agentic-rag-explained',\n",
       "   'title': 'Agentic RAG explained: Smarter retrieval with AI agents - Glean',\n",
       "   'content': 'Agentic RAG is a next-generation implementation of retrieval-augmented generation. It enhances traditional RAG systems by incorporating AI agents.',\n",
       "   'score': 0.94289196,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 1.87,\n",
       " 'request_id': '58f61e2d-2e28-46fc-b4ec-ff5a9d622ca5'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tavily_search = TavilySearch(\n",
    "    api_key=settings.TAVILY_API_KEY.get_secret_value(),\n",
    "    max_results=2,\n",
    "    topic=\"general\",\n",
    ")\n",
    "search_response = tavily_search.invoke({\"query\": \"What is agentic RAG?\"})\n",
    "search_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a0d0065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from markdownify import markdownify\n",
    "\n",
    "\n",
    "async def afetch_raw_content(url: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Asynchronously fetch HTML content from a URL and convert it to markdown format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        The URL to fetch content from.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str or None\n",
    "        The fetched content converted to markdown if successful,\n",
    "        None if any error occurs during fetching or conversion.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Uses a 10-second timeout to avoid hanging on slow sites or large pages.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a client with reasonable timeout\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            return markdownify(response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to fetch full page content for {url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# await afetch_raw_content(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd3187f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b6fccb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'snippet': 'In February 1981, Obama made his first public speech, calling for Occidental to participate in the disinvestment from South Africa in response to ...',\n",
       "  'title': 'Barack Obama - Wikipedia',\n",
       "  'link': 'https://en.wikipedia.org/wiki/Barack_Obama'},\n",
       " {'snippet': 'The elections of 1792 were the first ones in the United States that were contested on anything resembling a partisan basis.[20] ^ The 1796 presidential election was the first contested American presidential election and the only one in which a president and vice president were elected from opposing political parties.',\n",
       "  'title': 'List of presidents of the United States - Wikipedia',\n",
       "  'link': 'https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States'},\n",
       " {'snippet': \"... searching our database we found 1 possible solution for the: ... The solution we have for President Obama ' s first name has a total of 6 letters.\",\n",
       "  'title': \"President Obama's first name crossword clue\",\n",
       "  'link': 'http://mail.crosswordswithfriendsanswers.com/president-obamas-first-name-crossword-clue'},\n",
       " {'snippet': 'According to the BBC , Odinga claims Obama as a first cousin.) We should eschew guilt by association, but the echoes resound.',\n",
       "  'title': 'Barack Hussein Obama: What’s in a Name? – PJ Media',\n",
       "  'link': 'https://pjmedia.com/david-solway-2/2012/10/29/bho-whats-in-a-name-n9431'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = DuckDuckGoSearchResults(output_format=\"list\")\n",
    "\n",
    "search.invoke(\"Obama's first name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51eecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "\n",
    "async def duckduckgo_search(\n",
    "    query: str, fetch_full_page: bool = False\n",
    ") -> dict[str, list[dict[str, Any]]]:\n",
    "    try:\n",
    "        search = DuckDuckGoSearchResults(output_format=\"list\")\n",
    "        raw_results = await search.ainvoke(query)\n",
    "\n",
    "        # format the data\n",
    "        raw_results: list[dict[str, Any]] = [\n",
    "            {\n",
    "                \"title\": row[\"title\"],\n",
    "                \"url\": row[\"link\"],\n",
    "                \"content\": row[\"snippet\"],\n",
    "            }\n",
    "            for row in raw_results\n",
    "        ]\n",
    "\n",
    "        if fetch_full_page:\n",
    "            raw_results = [\n",
    "                {\n",
    "                    **row,\n",
    "                    **{\n",
    "                        \"raw_content\": await afetch_raw_content(row[\"url\"]),\n",
    "                    },\n",
    "                }\n",
    "                for row in raw_results\n",
    "            ]\n",
    "        return {\"results\": raw_results}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Duckduckgo search failed: {str(e)}\")\n",
    "        return {\"results\": []}\n",
    "\n",
    "\n",
    "async def google_search(\n",
    "    query: str, max_results: int = 3, fetch_full_page: bool = False\n",
    ") -> dict[str, list[dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Perform a web search using the GoogleSerperAPIWrapper.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "        The search query string.\n",
    "    max_results : int, optional\n",
    "        Maximum number of results to return (default is 3).\n",
    "    fetch_full_page : bool, optional\n",
    "        If True, fetch and include the full page content for each result (default is False).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, list[dict[str, Any]]]\n",
    "        Dictionary with a \"results\" key containing a list of result dictionaries.\n",
    "        Each result dictionary contains:\n",
    "            - \"title\": str, the result title\n",
    "            - \"url\": str, the result URL\n",
    "            - \"content\": str, the snippet or summary\n",
    "            - \"raw_content\": str, the full page content if fetched, otherwise the snippet\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Uses the GoogleSerperAPIWrapper for querying Google Serper. Handles errors gracefully.\n",
    "    \"\"\"\n",
    "    search = GoogleSerperAPIWrapper(k=max_results)\n",
    "\n",
    "    try:\n",
    "        raw_results = await search.aresults(query)\n",
    "\n",
    "        results = [\n",
    "            {\n",
    "                \"title\": res[\"title\"],\n",
    "                \"url\": res[\"link\"],\n",
    "                \"content\": res[\"snippet\"],\n",
    "                \"raw_content\": res[\"snippet\"],\n",
    "            }\n",
    "            for res in raw_results[\"organic\"]\n",
    "        ]\n",
    "        if fetch_full_page:\n",
    "            results = [\n",
    "                {\n",
    "                    **row,\n",
    "                    **{\n",
    "                        \"raw_content\": await afetch_raw_content(row[\"url\"]),\n",
    "                    },\n",
    "                }\n",
    "                for row in results\n",
    "            ]\n",
    "        return {\"results\": results}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Google search failed: {str(e)}\")\n",
    "        return {\"results\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c0e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await duckduckgo_search(\n",
    "    \"What was the result of Barcelona vs Madrid today?\", fetch_full_page=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2821e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await google_search(\n",
    "    \"What was the result of Barcelona vs Madrid today?\", fetch_full_page=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8646802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results': [{'title': 'Real Madrid vs Barcelona LIVE: El Clasico score, stats ... - BBC',\n",
       "   'url': 'https://www.bbc.com/sport/football/live/cn7ev2x750jt',\n",
       "   'content': 'Jude Bellingham scored and assisted for the first time in La Liga this season as Real Madrid overcame Barcelona in a breathless and fiery ...',\n",
       "   'raw_content': 'Jude Bellingham scored and assisted for the first time in La Liga this season as Real Madrid overcame Barcelona in a breathless and fiery ...'},\n",
       "  {'title': 'Real Madrid 2-1 Barcelona (Oct 26, 2025) Game Analysis - ESPN',\n",
       "   'url': 'https://www.espn.com/soccer/report/_/gameId/748236',\n",
       "   'content': 'Real Madrid ended its four-game losing streak against rival Barcelona with a 2-1 victory in the first El Clásico of the season on Sunday.',\n",
       "   'raw_content': 'Real Madrid ended its four-game losing streak against rival Barcelona with a 2-1 victory in the first El Clásico of the season on Sunday.'},\n",
       "  {'title': 'Real Madrid 2-1 Barcelona: El Clásico score stats and highlights',\n",
       "   'url': 'https://en.as.com/soccer/real-madrid-vs-barcelona-live-online-el-clasico-score-stats-goals-updates-laliga-202526-f202510-d/',\n",
       "   'content': 'Goals from Kylian Mbappe and Jude Bellingham gave Real Madrid a 2-1 win over Barcelona on Sunday, giving Xabi Alonso his first El Clasico win as ...',\n",
       "   'raw_content': 'Goals from Kylian Mbappe and Jude Bellingham gave Real Madrid a 2-1 win over Barcelona on Sunday, giving Xabi Alonso his first El Clasico win as ...'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84b02c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Goals from Kylian Mbappe and Jude Bellingham gave Real Madrid a <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> win over Barcelona on Sunday, giving Xabi \n",
       "Alonso his first El Clasico win as <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Goals from Kylian Mbappe and Jude Bellingham gave Real Madrid a \u001b[1;36m2\u001b[0m-\u001b[1;36m1\u001b[0m win over Barcelona on Sunday, giving Xabi \n",
       "Alonso his first El Clasico win as \u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(res[\"results\"][2][\"raw_content\"][:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac53097c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65b50b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def day_name_tool(year: int, month: int, day: int) -> str:\n",
    "    \"\"\"Determine the name of the day for a given date.\n",
    "    Parameters\n",
    "    ----------\n",
    "    year : int\n",
    "        The year for which to generate the calendar (e.g., 2025).\n",
    "    month : int\n",
    "        The month for which to generate the calendar (1-12).\n",
    "    day : int\n",
    "        The day of the month (not used in calendar generation).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The name of the day for the given date.\n",
    "    \"\"\"\n",
    "    if not isinstance(year, int) or year < 1:\n",
    "        raise ValueError(\"Year must be a positive integer.\")\n",
    "    if not isinstance(month, int):\n",
    "        raise ValueError(\"Month must be an integer.\")\n",
    "    if not isinstance(day, int):\n",
    "        raise ValueError(\"Day must be an integer.\")\n",
    "    if not (1 <= month <= 12):\n",
    "        raise ValueError(\"Month must be between 1 and 12.\")\n",
    "    if not (1 <= day <= 31):\n",
    "        raise ValueError(\"Day must be between 1 and 31.\")\n",
    "\n",
    "    return calendar.day_name[calendar.weekday(year, month, day)]\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "async def search_tool(query: str, max_chars: int = 500) -> tuple[str, dict]:\n",
    "    \"\"\"Perform a search using TavilySearch tool.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    query: str\n",
    "        The search query.\n",
    "    max_chars: int, default=1000\n",
    "        The maximum number of characters per source to return from the search results.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        The formatted search results.\n",
    "    \"\"\"\n",
    "    separator: str = \"\\n\\n\"\n",
    "\n",
    "    tavily_search = TavilySearch(\n",
    "        api_key=settings.TAVILY_API_KEY.get_secret_value(),\n",
    "        max_results=3,\n",
    "        topic=\"general\",\n",
    "    )\n",
    "    search_response = await tavily_search.ainvoke({\"query\": query})\n",
    "    formatted_results: str = \"\\n\\n\".join(\n",
    "        f\"Title: {result['title']}\\nContent: {result['content'][:max_chars]} [truncated]\\nURL: {result['url']}{separator}\"\n",
    "        for result in search_response[\"results\"]\n",
    "    )\n",
    "    return formatted_results, search_response\n",
    "\n",
    "\n",
    "@tool(response_format=\"content\")\n",
    "def date_and_time_tool() -> str:\n",
    "    \"\"\"\n",
    "    Get the current date, time, and day name as a string.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The current date, time, and day name as a string.\n",
    "    \"\"\"\n",
    "    raw_date: str = datetime.now().isoformat()\n",
    "    date: str = raw_date.split(\"T\")[0]\n",
    "    time: str = raw_date.split(\"T\")[-1]\n",
    "\n",
    "    day_name: str = day_name_tool(\n",
    "        year=int(date.split(\"-\")[0]),\n",
    "        month=int(date.split(\"-\")[1]),\n",
    "        day=int(date.split(\"-\")[2]),\n",
    "    )\n",
    "\n",
    "    return f\"Date: {date}\\n\\nTime: {time} (GMT+1)\\n\\nDay Name: {day_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8569c7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">StructuredTool</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'search_tool'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">description</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Perform a search using TavilySearch tool.\\n\\n    Parameters:\\n    -----------\\n    query: str\\n   </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The search query.\\n    max_chars: int, default=1000\\n        The maximum number of characters per source to return </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from the search results.\\n\\n    Returns:\\n    --------\\n    str\\n        The formatted search results.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">args_schema</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'langchain_core.utils.pydantic.search_tool'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">response_format</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'content_and_artifact'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">coroutine</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;function search_tool at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x12aee9260</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mStructuredTool\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mname\u001b[0m=\u001b[32m'search_tool'\u001b[0m,\n",
       "    \u001b[33mdescription\u001b[0m=\u001b[32m'Perform a search using TavilySearch tool.\\n\\n    Parameters:\\n    -----------\\n    query: str\\n   \u001b[0m\n",
       "\u001b[32mThe search query.\\n    max_chars: int, \u001b[0m\u001b[32mdefault\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1000\u001b[0m\u001b[32m\\n        The maximum number of characters per source to return \u001b[0m\n",
       "\u001b[32mfrom the search results.\\n\\n    Returns:\\n    --------\\n    str\\n        The formatted search results.'\u001b[0m,\n",
       "    \u001b[33margs_schema\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'langchain_core.utils.pydantic.search_tool'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mresponse_format\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'content_and_artifact'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mcoroutine\u001b[0m\u001b[39m=<function search_tool at \u001b[0m\u001b[1;36m0x12aee9260\u001b[0m\u001b[1m>\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(search_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "379a9cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Title: What is Agentic RAG? - GeeksforGeeks\n",
       "Content: Agentic RAG is an advanced version of Retrieval-Augmented Generation <span style=\"font-weight: bold\">(</span>RAG<span style=\"font-weight: bold\">)</span> where an AI agent retrieves \n",
       "external information and autonomously decides how to use \n",
       "URL: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.geeksforgeeks.org/artificial-intelligence/what-is-agentic-rag/</span>\n",
       "\n",
       "\n",
       "\n",
       "Title: What is Agentic RAG? | IBM\n",
       "Content: # What is agentic RAG? Agentic RAG is the use of AI agents to facilitate retrieval augmented generation \n",
       "<span style=\"font-weight: bold\">(</span>RAG<span style=\"font-weight: bold\">)</span>. Agentic RAG systems add AI agents to the RAG pipeline to increase adaptability and accuracy. Compared to \n",
       "traditional RAG systems, agentic RAG allows large language models <span style=\"font-weight: bold\">(</span>LLMs<span style=\"font-weight: bold\">)</span> to conduct information retrieval from \n",
       "multiple sources and handle more complex workflows. ### What is agentic AI? AI agents ### What are AI agents? ## \n",
       "How does agentic RAG work? Agentic RAG works by incorporatin \n",
       "URL: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.ibm.com/think/topics/agentic-rag</span>\n",
       "\n",
       "\n",
       "\n",
       "Title: Agentic RAG: A Guide to Building Autonomous AI Systems - n8n Blog\n",
       "Content: Agentic RAG is about the intelligence and autonomy of the system's decision-making and workflow execution.\n",
       "Graph RAG is about the structure and \n",
       "URL: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://blog.n8n.io/agentic-rag/</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Title: What is Agentic RAG? - GeeksforGeeks\n",
       "Content: Agentic RAG is an advanced version of Retrieval-Augmented Generation \u001b[1m(\u001b[0mRAG\u001b[1m)\u001b[0m where an AI agent retrieves \n",
       "external information and autonomously decides how to use \n",
       "URL: \u001b[4;94mhttps://www.geeksforgeeks.org/artificial-intelligence/what-is-agentic-rag/\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "Title: What is Agentic RAG? | IBM\n",
       "Content: # What is agentic RAG? Agentic RAG is the use of AI agents to facilitate retrieval augmented generation \n",
       "\u001b[1m(\u001b[0mRAG\u001b[1m)\u001b[0m. Agentic RAG systems add AI agents to the RAG pipeline to increase adaptability and accuracy. Compared to \n",
       "traditional RAG systems, agentic RAG allows large language models \u001b[1m(\u001b[0mLLMs\u001b[1m)\u001b[0m to conduct information retrieval from \n",
       "multiple sources and handle more complex workflows. ### What is agentic AI? AI agents ### What are AI agents? ## \n",
       "How does agentic RAG work? Agentic RAG works by incorporatin \n",
       "URL: \u001b[4;94mhttps://www.ibm.com/think/topics/agentic-rag\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "Title: Agentic RAG: A Guide to Building Autonomous AI Systems - n8n Blog\n",
       "Content: Agentic RAG is about the intelligence and autonomy of the system's decision-making and workflow execution.\n",
       "Graph RAG is about the structure and \n",
       "URL: \u001b[4;94mhttps://blog.n8n.io/agentic-rag/\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "formatted_results, search_response = await search_tool.coroutine(\"what is agentic RAG?\")\n",
    "console.print(formatted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93680cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(search_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70973b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_and_time_tool.func()\n",
    "\n",
    "# console.print(date_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e78836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_system_message: str = \"\"\"\n",
    "<SYSTEM>\n",
    "    <ROLE>You are a knowledgeable and helpful chatbot assistant.</ROLE>\n",
    "\n",
    "    <GUIDELINES>\n",
    "    - Provide clear, accurate, and contextually relevant answers based on the user's input.\n",
    "    - Use available tools to ensure responses are current and reliable.\n",
    "    - Keep responses focused, concise, and directly related to the conversation.\n",
    "    - If information is insufficient, politely ask for clarification.\n",
    "    - Limit responses to a maximum of five sentences.\n",
    "    </GUIDELINES>\n",
    "</SYSTEM>\n",
    "\"\"\"\n",
    "\n",
    "query_prompt: str = \"\"\"\n",
    "<USER>\n",
    "    <QUERY>{query}</QUERY>\n",
    "</USER>\n",
    "\"\"\"\n",
    "\n",
    "summary_prompt: str = \"\"\"\n",
    "<USER>\n",
    "    <GUIDELINES>\n",
    "        - Expand the summary by incorporating the the above conversation while preserving context, key points, and\n",
    "        user intent. \n",
    "        - Rework the summary if needed. Ensure that no critical information is lost and that the \n",
    "        conversation can continue naturally without gaps. \n",
    "        - Keep the summary concise yet informative, removing unnecessary repetition while maintaining clarity.\n",
    "        - Only return the updated summary. Do not add explanations, section headers, or extra commentary.\n",
    "    </GUIDELINES>\n",
    "\n",
    "    <SUMMARY>{summary}</SUMMARY>\n",
    "\n",
    "</USER>\n",
    "\"\"\"\n",
    "\n",
    "no_summary_prompt: str = \"\"\"\n",
    "<USER>\n",
    "    <GUIDELINES>\n",
    "    - Summarize the conversation above while preserving full context, key points, and user intent. \n",
    "    - Your response should be concise yet detailed enough to ensure seamless continuation of the discussion.\n",
    "    - Avoid redundancy, maintain clarity, and retain all necessary details for future exchanges.\n",
    "    - Only return the summarized content. Do not add explanations, section headers, or extra commentary.\n",
    "    </GUIDELINES>\n",
    "\n",
    "</USER>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89d86d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Annotated, TypedDict\n",
    "# from uuid import uuid4\n",
    "\n",
    "# from IPython.display import Image, Markdown, display\n",
    "# from langchain.messages import RemoveMessage\n",
    "# from langchain_core.messages import (\n",
    "#     AIMessage,\n",
    "#     AnyMessage,\n",
    "#     HumanMessage,\n",
    "#     SystemMessage,\n",
    "#     ToolMessage,\n",
    "# )\n",
    "# from langchain_core.messages.utils import count_tokens_approximately\n",
    "# from langgraph.checkpoint.memory import MemorySaver\n",
    "# from langgraph.graph import END, START, StateGraph\n",
    "# from langgraph.graph.message import add_messages\n",
    "# from langgraph.prebuilt import ToolNode, tools_condition\n",
    "# from langgraph.types import RetryPolicy\n",
    "# from langmem.short_term import RunningSummary, SummarizationNode\n",
    "# from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505711da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain.messages import RemoveMessage\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    AnyMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9271419e",
   "metadata": {},
   "source": [
    "### Remove Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28d16f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Message 1', additional_kwargs={}, response_metadata={}, id='1'),\n",
       " AIMessage(content='Message 2', additional_kwargs={}, response_metadata={}, id='2'),\n",
       " HumanMessage(content='Message 3', additional_kwargs={}, response_metadata={}, id='3'),\n",
       " AIMessage(content='Message 4', additional_kwargs={}, response_metadata={}, id='4'),\n",
       " HumanMessage(content='Message 5', additional_kwargs={}, response_metadata={}, id='5'),\n",
       " AIMessage(content='Message 6', additional_kwargs={}, response_metadata={}, id='6'),\n",
       " HumanMessage(content='Message 7', additional_kwargs={}, response_metadata={}, id='7'),\n",
       " AIMessage(content='Message 8', additional_kwargs={}, response_metadata={}, id='8')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_msgs = [\n",
    "    HumanMessage(content=\"Message 1\", id=1),\n",
    "    AIMessage(content=\"Message 2\", id=2),\n",
    "    HumanMessage(content=\"Message 3\", id=3),\n",
    "    AIMessage(\n",
    "        content=\"Message 4\",\n",
    "        id=4,\n",
    "    ),\n",
    "    HumanMessage(content=\"Message 5\", id=5),\n",
    "]\n",
    "\n",
    "new_messages = [\n",
    "    AIMessage(\n",
    "        content=\"Message 6\",\n",
    "        id=6,\n",
    "    ),\n",
    "    HumanMessage(content=\"Message 7\", id=7),\n",
    "    AIMessage(content=\"Message 8\", id=8),\n",
    "]\n",
    "\n",
    "messages = add_messages(existing_msgs, new_messages)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70a2c055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='1'),\n",
       " RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='2'),\n",
       " RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='3'),\n",
       " RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='4'),\n",
       " RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='5'),\n",
       " RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='6')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove messages except the last 2\n",
    "messages_to_remove = [RemoveMessage(id=m.id) for m in messages[:-2]]\n",
    "messages_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd397934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Message 7', additional_kwargs={}, response_metadata={}, id='7'),\n",
       " AIMessage(content='Message 8', additional_kwargs={}, response_metadata={}, id='8')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_messages = add_messages(messages, messages_to_remove)\n",
    "updated_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3016b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1db2d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.types import RetryPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a689c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# =========================== STATES ============================\n",
    "# ===============================================================\n",
    "class MetaState(TypedDict):\n",
    "    query: str\n",
    "    answer: str\n",
    "\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "class State(MetaState):\n",
    "    summary: str\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# ============================ LLMS =============================\n",
    "# ===============================================================\n",
    "MAX_SUMMARY_TOKENS: int = 2048\n",
    "MAX_MESSAGES: int = 10\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=settings.OPENROUTER_API_KEY.get_secret_value(),  # type: ignore\n",
    "    base_url=settings.OPENROUTER_URL,\n",
    "    temperature=0.02,\n",
    "    model=RemoteModel.GEMINI_2_0_FLASH_001,\n",
    ")\n",
    "summarization_llm = ChatOpenAI(\n",
    "    api_key=settings.OPENROUTER_API_KEY.get_secret_value(),  # type: ignore\n",
    "    base_url=settings.OPENROUTER_URL,\n",
    "    temperature=0.0,\n",
    "    model=RemoteModel.QWEN3_30B_A3B,\n",
    ").bind(max_tokens=MAX_SUMMARY_TOKENS)\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# ============================ NODES ============================\n",
    "# ===============================================================\n",
    "async def call_llm(state: State) -> State:\n",
    "    \"\"\"Call the LLM with the current state and return the updated state.\"\"\"\n",
    "    summary: str = state.get(\"summary\", \"\")\n",
    "    sys_msg = SystemMessage(content=chatbot_system_message)\n",
    "\n",
    "    if summary:\n",
    "        summary_msg = SystemMessage(content=f\"Summary of conversation:\\n\\n {summary}\")\n",
    "        # Summary + most recent messages\n",
    "        msgs_with_summary = [summary_msg] + state[\"messages\"]\n",
    "\n",
    "    else:\n",
    "        msgs_with_summary = state[\"messages\"]\n",
    "\n",
    "    _msg = query_prompt.format(query=state.get(\"query\", \"\"))\n",
    "    query = HumanMessage(content=_msg)\n",
    "    llm_with_tools = llm.bind_tools(tools=[search_tool, date_and_time_tool])\n",
    "    response = await llm_with_tools.ainvoke([sys_msg] + msgs_with_summary + [query])\n",
    "\n",
    "    return State(\n",
    "        query=state.get(\"query\", \"\"),\n",
    "        answer=response.content,\n",
    "        messages=[state.get(\"query\", \"\"), response],\n",
    "        summary=summary,\n",
    "    )\n",
    "\n",
    "\n",
    "async def summarization_node(state: State) -> State:\n",
    "    \"\"\"Summarize the conversation in the state and return the updated state.\"\"\"\n",
    "    summary: str = state.get(\"summary\", \"\")\n",
    "\n",
    "    if summary:\n",
    "        summary_msg: list[AnyMessage] = [\n",
    "            HumanMessage(content=summary_prompt.format(summary=summary))\n",
    "        ]\n",
    "    else:\n",
    "        summary_msg = [HumanMessage(content=no_summary_prompt)]\n",
    "\n",
    "    response: AIMessage = await summarization_llm.ainvoke(\n",
    "        state[\"messages\"] + summary_msg\n",
    "    )\n",
    "\n",
    "    # Delete ALL but the last 2 messages\n",
    "    messages_to_remove = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "\n",
    "    return State(\n",
    "        query=state.get(\"query\", None),\n",
    "        answer=state.get(\"answer\", None),\n",
    "        messages=messages_to_remove,\n",
    "        summary=response.content,\n",
    "    )\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# =========================== EDGEs =============================\n",
    "# ===============================================================\n",
    "def should_summarize(state: State) -> Literal[\"summarize\", END]:\n",
    "    \"\"\"Decide whether to summarize based on the number of messages in the state.\"\"\"\n",
    "    if len(state[\"messages\"]) > MAX_MESSAGES:\n",
    "        return \"summarize\"\n",
    "\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a824064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langgraph.prebuilt import ToolNode, tools_condition\n",
    "# from langgraph.types import RetryPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605f64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_attempts: int = 2\n",
    "\n",
    "# Memory\n",
    "memory = MemorySaver()\n",
    "tool_node = ToolNode([search_tool, date_and_time_tool])\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Add Nodes\n",
    "builder.add_node(\n",
    "    \"call_llm\",\n",
    "    call_llm,\n",
    "    retry_policy=RetryPolicy(max_attempts=max_attempts, initial_interval=1.0),\n",
    ")\n",
    "builder.add_node(\n",
    "    \"tools\",\n",
    "    tool_node,\n",
    "    retry_policy=RetryPolicy(max_attempts=max_attempts, initial_interval=1.0),\n",
    ")\n",
    "builder.add_node(\n",
    "    \"summarize\",\n",
    "    summarization_node,\n",
    "    retry_policy=RetryPolicy(max_attempts=max_attempts, initial_interval=1.0),\n",
    ")\n",
    "\n",
    "# Add Edges\n",
    "# builder.add_conditional_edges(\n",
    "#     START, should_summarize, {\"summarize\": \"summarize\", \"call_llm\": \"call_llm\"}\n",
    "# )\n",
    "builder.add_edge(START, \"call_llm\")\n",
    "# builder.add_edge(\"call_llm\", \"summarize\")\n",
    "builder.add_conditional_edges(\"call_llm\", tools_condition, {\"tools\": \"tools\", END: END})\n",
    "builder.add_conditional_edges(\n",
    "    \"call_llm\", should_summarize, {\"summarize\": \"summarize\", END: END}\n",
    ")\n",
    "builder.add_edge(\"tools\", \"call_llm\")\n",
    "\n",
    "# Build the graph\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "# Visualize the graph with ASCII fallback\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    console.print(f\"[yellow]PNG visualization failed: {e}[/yellow]\")\n",
    "    console.print(\"[cyan]Displaying ASCII representation instead:[/cyan]\\n\")\n",
    "    try:\n",
    "        print(graph.get_graph(xray=1).draw_ascii())\n",
    "    except ImportError as ie:\n",
    "        console.print(f\"[red]ASCII visualization also failed: {ie}[/red]\")\n",
    "        console.print(\"[magenta]Showing basic graph structure:[/magenta]\\n\")\n",
    "        graph_obj = graph.get_graph(xray=1)\n",
    "        console.print(f\"Nodes: {[node.id for node in graph_obj.nodes.values()]}\")\n",
    "        console.print(f\"Edges: {[(e.source, e.target) for e in graph_obj.edges]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a990dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': HumanMessage(content=\"Hello, I'm neidu. Tell me a joke\", additional_kwargs={}, response_metadata={}, id='ef26acff-f8ac-44f9-acb8-608bb2508aaf'),\n",
       " 'answer': 'I am sorry, I cannot fulfill this request. The search results do not contain a joke, but rather an app and a song.\\n',\n",
       " 'messages': [HumanMessage(content=\"Hello, I'm neidu. Tell me a joke\", additional_kwargs={}, response_metadata={}, id='ef26acff-f8ac-44f9-acb8-608bb2508aaf'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 281, 'total_tokens': 293, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110425-sXvalgO1UzgVokRHYq03', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--b7d3afe4-408e-4cd7-bb80-18da50579eea-0', tool_calls=[{'name': 'search_tool', 'args': {'max_chars': 500, 'query': 'tell me a joke'}, 'id': 'tool_0_search_tool_NaXOQYicxlasAcprceXc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 281, 'output_tokens': 12, 'total_tokens': 293, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "  ToolMessage(content='Title: Tell Me A Joke! - Apps on Google Play\\nContent: # Tell Me A Joke! With its advanced text-to-speech system, this ingenious app will let you enjoy hilarious jokes anytime, told with a captivating voice. Just launch the app and select your favorite category from a huge collection of classic, humorous, or even the latest jokes. The application \"Tell me a joke!\" doesn\\'t just make you laugh, it also lets you share those comedic moments with your loved ones. Download now \"Tell me a joke!\" on your device, and let yourself be carried away by a series  [truncated]\\nURL: https://play.google.com/store/apps/details?id=org.purpletentacle.TellMeAJoke&hl=en_US\\n\\n\\n\\nTitle: Quadeca - Tell Me A Joke (Official Video)\\nContent: boom here is the new official music video for Tell Me A Joke by Quadeca. This is the 2nd and last single for my new album “I Didn\\'t Mean to [truncated]\\nURL: https://www.youtube.com/watch?v=twQ6kKjtBkY\\n\\n\\n\\nTitle: “Ok Google, tell me a joke”\\nContent: “Ok Google, tell me a joke” # “Ok Google, tell me a joke” The Google Assistant Team Here are a couple of our favorites: * You: “Ok Google, tell me a joke.” * Google Assistant: “One joke, coming up! What is a sea monster’s favorite snack? * You: “Ok Google, tell me a joke.” * Google Assistant: “This might make you laugh. #### The Assistant experience on mobile is upgrading to Gemini Over the coming months, we’ll be upgrading users on mobile devices from Google Assistant to Gemini. Google Assistan [truncated]\\nURL: https://blog.google/products/assistant/ok-google-tell-me-a-joke/\\n\\n', name='search_tool', id='0673fd81-3b7a-466a-b77b-82c22090e51a', tool_call_id='tool_0_search_tool_NaXOQYicxlasAcprceXc', artifact={'query': 'tell me a joke', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://play.google.com/store/apps/details?id=org.purpletentacle.TellMeAJoke&hl=en_US', 'title': 'Tell Me A Joke! - Apps on Google Play', 'content': '# Tell Me A Joke! With its advanced text-to-speech system, this ingenious app will let you enjoy hilarious jokes anytime, told with a captivating voice. Just launch the app and select your favorite category from a huge collection of classic, humorous, or even the latest jokes. The application \"Tell me a joke!\" doesn\\'t just make you laugh, it also lets you share those comedic moments with your loved ones. Download now \"Tell me a joke!\" on your device, and let yourself be carried away by a series of laughs and smiles. Safety starts with understanding how developers collect and share your data. This joke can not be found. Tell me a joke. tmaj.purple.tentacle@gmail.com', 'score': 0.86331123, 'raw_content': None}, {'url': 'https://www.youtube.com/watch?v=twQ6kKjtBkY', 'title': 'Quadeca - Tell Me A Joke (Official Video)', 'content': \"boom here is the new official music video for Tell Me A Joke by Quadeca. This is the 2nd and last single for my new album “I Didn't Mean to\", 'score': 0.7368747, 'raw_content': None}, {'url': 'https://blog.google/products/assistant/ok-google-tell-me-a-joke/', 'title': '“Ok Google, tell me a joke”', 'content': '“Ok Google, tell me a joke” # “Ok Google, tell me a joke” The Google Assistant Team Here are a couple of our favorites: * You: “Ok Google, tell me a joke.” * Google Assistant: “One joke, coming up! What is a sea monster’s favorite snack? * You: “Ok Google, tell me a joke.” * Google Assistant: “This might make you laugh. #### The Assistant experience on mobile is upgrading to Gemini Over the coming months, we’ll be upgrading users on mobile devices from Google Assistant to Gemini. Google Assistant #### Changes we’re making to Google Assistant Google Assistant Google Assistant #### Talk to Google Assistant and Alexa on new JBL Authentics speakers #### 8 ways Google tools help me care for my pets', 'score': 0.67911536, 'raw_content': None}], 'response_time': 1.58, 'request_id': '46160e53-4173-4803-8598-58df2a696f76'}),\n",
       "  AIMessage(content='I am sorry, I cannot fulfill this request. The search results do not contain a joke, but rather an app and a song.\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 760, 'total_tokens': 788, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110429-Y9YKDnO2567BXoAZvhFI', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--e0319aa1-206f-419a-bfc6-ebaf020394be-0', usage_metadata={'input_tokens': 760, 'output_tokens': 28, 'total_tokens': 788, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})],\n",
       " 'summary': ''}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-build the graph\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "config: dict[str, Any] = {\"configurable\": {\"thread_id\": \"test-01\"}}\n",
    "response = await graph.ainvoke(\n",
    "    {\"query\": HumanMessage(\"Hello, I'm neidu. Tell me a joke\")},\n",
    "    config=config,  # type: ignore\n",
    ")\n",
    "\n",
    "# for message in response[\"messages\"][-2:]:\n",
    "#     message.pretty_print()\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8c9915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# msg: str = \"Who was the first Nigerian Catholic priest in Nigeria?\"\n",
    "msg: str = \"What's today's date? and What day is tomorrow?\"\n",
    "# msg: str = \"What is my name?\"\n",
    "# msg: str = \"What is langgraph? Which is better between langgraph and AutoGen?\"\n",
    "response = await graph.ainvoke({\"query\": HumanMessage(msg)}, config=config)\n",
    "\n",
    "# for message in response[\"messages\"][-2:]:\n",
    "#     message.pretty_print()\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ffccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the latest state snapshot\n",
    "print(graph.get_state(config))\n",
    "\n",
    "state_snapshot = graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the attributes and methods of the state snapshot\n",
    "for attr in dir(state_snapshot):\n",
    "    if not attr.startswith(\"__\"):\n",
    "        print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb1cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_snapshot.values\n",
    "# state_snapshot._field_defaults\n",
    "# state_snapshot.created_at\n",
    "state_snapshot._asdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all the messages in the state snapshot\n",
    "history_messages = state_snapshot.values[\"messages\"]\n",
    "history_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86923a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "console.print(history_messages[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307dfc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(history_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10520270",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_msgs = []\n",
    "\n",
    "for row in history_messages:\n",
    "    if hasattr(row, \"content\") and hasattr(row, \"type\"):\n",
    "        if row.type in [\"ai\", \"human\"] and row.content:\n",
    "            formatted_msgs.append({\"role\": row.type, \"content\": row.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32165a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13295b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "row.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fede90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from typing import Any, Sequence\n",
    "\n",
    "\n",
    "def truncate_text(text: str, limit: int = 120) -> str:\n",
    "    \"\"\"Shorten long text for readability.\"\"\"\n",
    "    text = str(text).replace(\"\\n\", \" \").strip()\n",
    "    return (text[:limit] + \"...\") if len(text) > limit else text\n",
    "\n",
    "\n",
    "def p_print(data: Any, indent: int = 2, width: int = 100) -> None:\n",
    "    \"\"\"Pretty-print message histories or any structured data.\"\"\"\n",
    "    printer = pprint.PrettyPrinter(\n",
    "        indent=indent, width=width, compact=False, sort_dicts=False\n",
    "    )\n",
    "\n",
    "    def print_dict_message(msg: dict, idx: int) -> None:\n",
    "        role = msg.get(\"role\", \"unknown\").capitalize()\n",
    "        content = msg.get(\"content\", \"\")\n",
    "        print(f\"\\n--- Message {idx} ---\")\n",
    "        print(f\"👤 Role: {role}\")\n",
    "        print(f\"💬 Content: {truncate_text(content)}\")\n",
    "\n",
    "    def print_object_message(msg: Any, idx: int) -> None:\n",
    "        msg_type = getattr(msg, \"__class__\", type(\"\")).__name__\n",
    "        print(f\"\\n--- Message {idx} ---\")\n",
    "        print(f\"==================== {msg_type} ====================\")\n",
    "\n",
    "        if hasattr(msg, \"id\"):\n",
    "            print(f\"🆔 ID: {msg.id}\")\n",
    "        if hasattr(msg, \"content\"):\n",
    "            print(f\"💬 Content: {truncate_text(msg.content)}\")\n",
    "\n",
    "        # Optional sections\n",
    "        for attr, label in [\n",
    "            (\"tool_calls\", \"🧰 Tool Calls\"),\n",
    "            (\"artifact\", \"📦 Artifact\"),\n",
    "            (\"response_metadata\", \"📊 Metadata\"),\n",
    "            (\"usage_metadata\", \"📈 Usage Metadata\"),\n",
    "        ]:\n",
    "            value = getattr(msg, attr, None)\n",
    "            if value:\n",
    "                print(f\"\\n{label}:\")\n",
    "                printer.pprint(value)\n",
    "\n",
    "    # Main logic\n",
    "    if isinstance(data, Sequence) and not isinstance(data, (str, bytes)):\n",
    "        print(f\"🧾 Message History ({len(data)} messages)\")\n",
    "\n",
    "        for idx, msg in enumerate(data, 1):\n",
    "            # ✅ Explicitly handle dicts first\n",
    "            if isinstance(msg, dict):\n",
    "                print_dict_message(msg, idx)\n",
    "            else:\n",
    "                print_object_message(msg, idx)\n",
    "    else:\n",
    "        printer.pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae9c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_print(history_messages[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c90ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bba38c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State history\n",
    "list(graph.get_state_history(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99457139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c61feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adce11e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "708b6df7",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2d678e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MESSAGES: int = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1159488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), 'messages': []}\n",
      "{'query': HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), 'answer': 'Hello neidu, how can I help you today?\\n', 'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}\n"
     ]
    }
   ],
   "source": [
    "# Re-build the graph\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "config: dict[str, Any] = {\"configurable\": {\"thread_id\": \"test-02\"}}\n",
    "response = graph.astream(\n",
    "    {\"query\": HumanMessage(\"Hello, I'm neidu\")},\n",
    "    config=config,  # type: ignore\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "async for chunk in response:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88abb397",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.astream(\n",
    "    {\"query\": HumanMessage(\"What's my name?\")},\n",
    "    config=config,  # type: ignore\n",
    "    stream_mode=\"messages\",\n",
    ")\n",
    "\n",
    "async for chunk in response:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc8d168",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Real-time Response Streaming (astream_events)\n",
    "\n",
    "- Use `astream_events` to get real-time events as they occur in the graph execution.\n",
    "- Useful for creating dynamic UIs or dashboards that update in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88359ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={})}}, 'name': 'LangGraph', 'tags': [], 'run_id': 'edc494b8-b139-4049-8cd1-297cfd47bb7d', 'metadata': {'thread_id': 'test-02'}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}), 'answer': 'Hello neidu, how can I help you today?\\n', 'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}, 'name': 'call_llm', 'tags': ['graph:step:4'], 'run_id': '9ac92188-1c64-480f-86bb-30e57b3592c1', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d']}\n",
      "{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[SystemMessage(content=\"\\n<SYSTEM>\\n    <ROLE>You are a knowledgeable and helpful chatbot assistant.</ROLE>\\n\\n    <GUIDELINES>\\n    - Provide clear, accurate, and contextually relevant answers based on the user's input.\\n    - Use available tools to ensure responses are current and reliable.\\n    - Keep responses focused, concise, and directly related to the conversation.\\n    - If information is insufficient, politely ask for clarification.\\n    - Limit responses to a maximum of five sentences.\\n    </GUIDELINES>\\n</SYSTEM>\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content='\\n<USER>\\n    <QUERY>content=\"What is tomorrow\\'s date?\" additional_kwargs={} response_metadata={}</QUERY>\\n</USER>\\n', additional_kwargs={}, response_metadata={})]]}}, 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'run_id': 'bc4e517b-2775-4f83-8eae-84f532d1b235', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960', 'checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960', 'ls_provider': 'openai', 'ls_model_name': 'google/gemini-2.0-flash-001', 'ls_model_type': 'chat', 'ls_temperature': 0.02}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '9ac92188-1c64-480f-86bb-30e57b3592c1']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'date_and_time_tool', 'args': '{}', 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'index': 0, 'type': 'tool_call_chunk'}], chunk_position='last')}, 'run_id': 'bc4e517b-2775-4f83-8eae-84f532d1b235', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960', 'checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960', 'ls_provider': 'openai', 'ls_model_name': 'google/gemini-2.0-flash-001', 'ls_model_type': 'chat', 'ls_temperature': 0.02}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '9ac92188-1c64-480f-86bb-30e57b3592c1']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})}, 'run_id': 'bc4e517b-2775-4f83-8eae-84f532d1b235', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960', 'checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960', 'ls_provider': 'openai', 'ls_model_name': 'google/gemini-2.0-flash-001', 'ls_model_type': 'chat', 'ls_temperature': 0.02}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '9ac92188-1c64-480f-86bb-30e57b3592c1']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', chunk_position='last')}, 'run_id': 'bc4e517b-2775-4f83-8eae-84f532d1b235', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960', 'checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960', 'ls_provider': 'openai', 'ls_model_name': 'google/gemini-2.0-flash-001', 'ls_model_type': 'chat', 'ls_temperature': 0.02}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '9ac92188-1c64-480f-86bb-30e57b3592c1']}\n",
      "{'event': 'on_chat_model_end', 'data': {'output': AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), 'input': {'messages': [[SystemMessage(content=\"\\n<SYSTEM>\\n    <ROLE>You are a knowledgeable and helpful chatbot assistant.</ROLE>\\n\\n    <GUIDELINES>\\n    - Provide clear, accurate, and contextually relevant answers based on the user's input.\\n    - Use available tools to ensure responses are current and reliable.\\n    - Keep responses focused, concise, and directly related to the conversation.\\n    - If information is insufficient, politely ask for clarification.\\n    - Limit responses to a maximum of five sentences.\\n    </GUIDELINES>\\n</SYSTEM>\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content='\\n<USER>\\n    <QUERY>content=\"What is tomorrow\\'s date?\" additional_kwargs={} response_metadata={}</QUERY>\\n</USER>\\n', additional_kwargs={}, response_metadata={})]]}}, 'run_id': 'bc4e517b-2775-4f83-8eae-84f532d1b235', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960', 'checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960', 'ls_provider': 'openai', 'ls_model_name': 'google/gemini-2.0-flash-001', 'ls_model_type': 'chat', 'ls_temperature': 0.02, 'revision_id': 'f1ac15a-dirty'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '9ac92188-1c64-480f-86bb-30e57b3592c1']}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': '', 'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}, 'name': 'tools_condition', 'tags': ['seq:step:3'], 'run_id': '7076d623-65dd-42a6-9428-1075e3f72c2d', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '9ac92188-1c64-480f-86bb-30e57b3592c1']}\n",
      "{'event': 'on_chain_end', 'data': {'output': 'tools', 'input': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': '', 'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}, 'run_id': '7076d623-65dd-42a6-9428-1075e3f72c2d', 'name': 'tools_condition', 'tags': ['seq:step:3'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960', 'revision_id': 'f1ac15a-dirty'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '9ac92188-1c64-480f-86bb-30e57b3592c1']}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': '', 'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}, 'name': 'should_summarize', 'tags': ['seq:step:4'], 'run_id': 'ea0d5fd3-5a44-4360-b02a-ba169b3ca9dc', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '9ac92188-1c64-480f-86bb-30e57b3592c1']}\n",
      "{'event': 'on_chain_end', 'data': {'output': '__end__', 'input': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': '', 'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}, 'run_id': 'ea0d5fd3-5a44-4360-b02a-ba169b3ca9dc', 'name': 'should_summarize', 'tags': ['seq:step:4'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960', 'revision_id': 'f1ac15a-dirty'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '9ac92188-1c64-480f-86bb-30e57b3592c1']}\n",
      "{'event': 'on_chain_stream', 'run_id': '9ac92188-1c64-480f-86bb-30e57b3592c1', 'name': 'call_llm', 'tags': ['graph:step:4'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960'}, 'data': {'chunk': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': '', 'messages': [HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d']}\n",
      "{'event': 'on_chain_end', 'data': {'output': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': '', 'messages': [HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}, 'input': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': 'Hello neidu, how can I help you today?\\n', 'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}, 'run_id': '9ac92188-1c64-480f-86bb-30e57b3592c1', 'name': 'call_llm', 'tags': ['graph:step:4'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:354ebbf0-66d0-9b45-1fa3-6b27dfc5c960', 'revision_id': 'f1ac15a-dirty'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d']}\n",
      "{'event': 'on_chain_stream', 'run_id': 'edc494b8-b139-4049-8cd1-297cfd47bb7d', 'name': 'LangGraph', 'tags': [], 'metadata': {'thread_id': 'test-02'}, 'data': {'chunk': {'call_llm': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': '', 'messages': [HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': '', 'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}, 'name': 'tools', 'tags': ['graph:step:5'], 'run_id': '827200af-9e6e-46ac-97e1-85ce032cf537', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 5, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'tools:6f66deaf-954d-a8a1-851a-a5931b2ee202'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d']}\n",
      "{'event': 'on_tool_start', 'data': {'input': {}}, 'name': 'date_and_time_tool', 'tags': ['seq:step:1'], 'run_id': '2b0ab60a-3513-4223-b880-e06661dec8b8', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 5, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'tools:6f66deaf-954d-a8a1-851a-a5931b2ee202', 'checkpoint_ns': 'tools:6f66deaf-954d-a8a1-851a-a5931b2ee202'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '827200af-9e6e-46ac-97e1-85ce032cf537']}\n",
      "{'event': 'on_tool_end', 'data': {'output': ToolMessage(content='Date: 2025-11-02\\n\\nTime: 20:08:19.141281 (GMT+1)\\n\\nDay Name: Sunday', name='date_and_time_tool', tool_call_id='tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13'), 'input': {}}, 'run_id': '2b0ab60a-3513-4223-b880-e06661dec8b8', 'name': 'date_and_time_tool', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 5, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'tools:6f66deaf-954d-a8a1-851a-a5931b2ee202', 'checkpoint_ns': 'tools:6f66deaf-954d-a8a1-851a-a5931b2ee202', 'revision_id': 'f1ac15a-dirty'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '827200af-9e6e-46ac-97e1-85ce032cf537']}\n",
      "{'event': 'on_chain_stream', 'run_id': '827200af-9e6e-46ac-97e1-85ce032cf537', 'name': 'tools', 'tags': ['graph:step:5'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 5, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'tools:6f66deaf-954d-a8a1-851a-a5931b2ee202'}, 'data': {'chunk': {'messages': [ToolMessage(content='Date: 2025-11-02\\n\\nTime: 20:08:19.141281 (GMT+1)\\n\\nDay Name: Sunday', name='date_and_time_tool', tool_call_id='tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13')]}}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d']}\n",
      "{'event': 'on_chain_end', 'data': {'output': {'messages': [ToolMessage(content='Date: 2025-11-02\\n\\nTime: 20:08:19.141281 (GMT+1)\\n\\nDay Name: Sunday', name='date_and_time_tool', tool_call_id='tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13')]}, 'input': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': '', 'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}, 'run_id': '827200af-9e6e-46ac-97e1-85ce032cf537', 'name': 'tools', 'tags': ['graph:step:5'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 5, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'tools:6f66deaf-954d-a8a1-851a-a5931b2ee202', 'revision_id': 'f1ac15a-dirty'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d']}\n",
      "{'event': 'on_chain_stream', 'run_id': 'edc494b8-b139-4049-8cd1-297cfd47bb7d', 'name': 'LangGraph', 'tags': [], 'metadata': {'thread_id': 'test-02'}, 'data': {'chunk': {'tools': {'messages': [ToolMessage(content='Date: 2025-11-02\\n\\nTime: 20:08:19.141281 (GMT+1)\\n\\nDay Name: Sunday', name='date_and_time_tool', id='16485e18-ce47-4dba-8607-5927ac9978fb', tool_call_id='tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13')]}}}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': '', 'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), ToolMessage(content='Date: 2025-11-02\\n\\nTime: 20:08:19.141281 (GMT+1)\\n\\nDay Name: Sunday', name='date_and_time_tool', id='16485e18-ce47-4dba-8607-5927ac9978fb', tool_call_id='tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13')], 'summary': ''}}, 'name': 'call_llm', 'tags': ['graph:step:6'], 'run_id': '3fd6cc28-2a61-4005-880c-55283487627b', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 6, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d']}\n",
      "{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[SystemMessage(content=\"\\n<SYSTEM>\\n    <ROLE>You are a knowledgeable and helpful chatbot assistant.</ROLE>\\n\\n    <GUIDELINES>\\n    - Provide clear, accurate, and contextually relevant answers based on the user's input.\\n    - Use available tools to ensure responses are current and reliable.\\n    - Keep responses focused, concise, and directly related to the conversation.\\n    - If information is insufficient, politely ask for clarification.\\n    - Limit responses to a maximum of five sentences.\\n    </GUIDELINES>\\n</SYSTEM>\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), ToolMessage(content='Date: 2025-11-02\\n\\nTime: 20:08:19.141281 (GMT+1)\\n\\nDay Name: Sunday', name='date_and_time_tool', id='16485e18-ce47-4dba-8607-5927ac9978fb', tool_call_id='tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13'), HumanMessage(content='\\n<USER>\\n    <QUERY>content=\"What is tomorrow\\'s date?\" additional_kwargs={} response_metadata={} id=\\'a0c182be-410c-4d98-bcf0-22c3dab717fb\\'</QUERY>\\n</USER>\\n', additional_kwargs={}, response_metadata={})]]}}, 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'run_id': 'bd25b2c7-63f3-440e-8308-b7a83e009e05', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 6, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'ls_provider': 'openai', 'ls_model_name': 'google/gemini-2.0-flash-001', 'ls_model_type': 'chat', 'ls_temperature': 0.02}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '3fd6cc28-2a61-4005-880c-55283487627b']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=\"Tomorrow'\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--bd25b2c7-63f3-440e-8308-b7a83e009e05')}, 'run_id': 'bd25b2c7-63f3-440e-8308-b7a83e009e05', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 6, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'ls_provider': 'openai', 'ls_model_name': 'google/gemini-2.0-flash-001', 'ls_model_type': 'chat', 'ls_temperature': 0.02}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '3fd6cc28-2a61-4005-880c-55283487627b']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='s date is 2025-11-03.\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--bd25b2c7-63f3-440e-8308-b7a83e009e05')}, 'run_id': 'bd25b2c7-63f3-440e-8308-b7a83e009e05', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 6, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'ls_provider': 'openai', 'ls_model_name': 'google/gemini-2.0-flash-001', 'ls_model_type': 'chat', 'ls_temperature': 0.02}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '3fd6cc28-2a61-4005-880c-55283487627b']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bd25b2c7-63f3-440e-8308-b7a83e009e05', chunk_position='last')}, 'run_id': 'bd25b2c7-63f3-440e-8308-b7a83e009e05', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 6, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'ls_provider': 'openai', 'ls_model_name': 'google/gemini-2.0-flash-001', 'ls_model_type': 'chat', 'ls_temperature': 0.02}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '3fd6cc28-2a61-4005-880c-55283487627b']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--bd25b2c7-63f3-440e-8308-b7a83e009e05', usage_metadata={'input_tokens': 408, 'output_tokens': 18, 'total_tokens': 426, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})}, 'run_id': 'bd25b2c7-63f3-440e-8308-b7a83e009e05', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 6, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'ls_provider': 'openai', 'ls_model_name': 'google/gemini-2.0-flash-001', 'ls_model_type': 'chat', 'ls_temperature': 0.02}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '3fd6cc28-2a61-4005-880c-55283487627b']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--bd25b2c7-63f3-440e-8308-b7a83e009e05', chunk_position='last')}, 'run_id': 'bd25b2c7-63f3-440e-8308-b7a83e009e05', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 6, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'ls_provider': 'openai', 'ls_model_name': 'google/gemini-2.0-flash-001', 'ls_model_type': 'chat', 'ls_temperature': 0.02}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '3fd6cc28-2a61-4005-880c-55283487627b']}\n",
      "{'event': 'on_chat_model_end', 'data': {'output': AIMessage(content=\"Tomorrow's date is 2025-11-03.\\n\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bd25b2c7-63f3-440e-8308-b7a83e009e05', usage_metadata={'input_tokens': 408, 'output_tokens': 18, 'total_tokens': 426, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), 'input': {'messages': [[SystemMessage(content=\"\\n<SYSTEM>\\n    <ROLE>You are a knowledgeable and helpful chatbot assistant.</ROLE>\\n\\n    <GUIDELINES>\\n    - Provide clear, accurate, and contextually relevant answers based on the user's input.\\n    - Use available tools to ensure responses are current and reliable.\\n    - Keep responses focused, concise, and directly related to the conversation.\\n    - If information is insufficient, politely ask for clarification.\\n    - Limit responses to a maximum of five sentences.\\n    </GUIDELINES>\\n</SYSTEM>\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), ToolMessage(content='Date: 2025-11-02\\n\\nTime: 20:08:19.141281 (GMT+1)\\n\\nDay Name: Sunday', name='date_and_time_tool', id='16485e18-ce47-4dba-8607-5927ac9978fb', tool_call_id='tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13'), HumanMessage(content='\\n<USER>\\n    <QUERY>content=\"What is tomorrow\\'s date?\" additional_kwargs={} response_metadata={} id=\\'a0c182be-410c-4d98-bcf0-22c3dab717fb\\'</QUERY>\\n</USER>\\n', additional_kwargs={}, response_metadata={})]]}}, 'run_id': 'bd25b2c7-63f3-440e-8308-b7a83e009e05', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 6, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'ls_provider': 'openai', 'ls_model_name': 'google/gemini-2.0-flash-001', 'ls_model_type': 'chat', 'ls_temperature': 0.02, 'revision_id': 'f1ac15a-dirty'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '3fd6cc28-2a61-4005-880c-55283487627b']}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': \"Tomorrow's date is 2025-11-03.\\n\", 'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), ToolMessage(content='Date: 2025-11-02\\n\\nTime: 20:08:19.141281 (GMT+1)\\n\\nDay Name: Sunday', name='date_and_time_tool', id='16485e18-ce47-4dba-8607-5927ac9978fb', tool_call_id='tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13'), AIMessage(content=\"Tomorrow's date is 2025-11-03.\\n\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bd25b2c7-63f3-440e-8308-b7a83e009e05', usage_metadata={'input_tokens': 408, 'output_tokens': 18, 'total_tokens': 426, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}, 'name': 'tools_condition', 'tags': ['seq:step:3'], 'run_id': 'd8e186f0-c1bb-4d8d-97d7-c0b351c52009', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 6, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '3fd6cc28-2a61-4005-880c-55283487627b']}\n",
      "{'event': 'on_chain_end', 'data': {'output': '__end__', 'input': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': \"Tomorrow's date is 2025-11-03.\\n\", 'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), ToolMessage(content='Date: 2025-11-02\\n\\nTime: 20:08:19.141281 (GMT+1)\\n\\nDay Name: Sunday', name='date_and_time_tool', id='16485e18-ce47-4dba-8607-5927ac9978fb', tool_call_id='tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13'), AIMessage(content=\"Tomorrow's date is 2025-11-03.\\n\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bd25b2c7-63f3-440e-8308-b7a83e009e05', usage_metadata={'input_tokens': 408, 'output_tokens': 18, 'total_tokens': 426, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}, 'run_id': 'd8e186f0-c1bb-4d8d-97d7-c0b351c52009', 'name': 'tools_condition', 'tags': ['seq:step:3'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 6, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'revision_id': 'f1ac15a-dirty'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '3fd6cc28-2a61-4005-880c-55283487627b']}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': \"Tomorrow's date is 2025-11-03.\\n\", 'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), ToolMessage(content='Date: 2025-11-02\\n\\nTime: 20:08:19.141281 (GMT+1)\\n\\nDay Name: Sunday', name='date_and_time_tool', id='16485e18-ce47-4dba-8607-5927ac9978fb', tool_call_id='tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13'), AIMessage(content=\"Tomorrow's date is 2025-11-03.\\n\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bd25b2c7-63f3-440e-8308-b7a83e009e05', usage_metadata={'input_tokens': 408, 'output_tokens': 18, 'total_tokens': 426, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}, 'name': 'should_summarize', 'tags': ['seq:step:4'], 'run_id': '1c7ceaa5-2f51-4847-9bf7-79012aa83a39', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 6, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '3fd6cc28-2a61-4005-880c-55283487627b']}\n",
      "{'event': 'on_chain_end', 'data': {'output': '__end__', 'input': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': \"Tomorrow's date is 2025-11-03.\\n\", 'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), ToolMessage(content='Date: 2025-11-02\\n\\nTime: 20:08:19.141281 (GMT+1)\\n\\nDay Name: Sunday', name='date_and_time_tool', id='16485e18-ce47-4dba-8607-5927ac9978fb', tool_call_id='tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13'), AIMessage(content=\"Tomorrow's date is 2025-11-03.\\n\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bd25b2c7-63f3-440e-8308-b7a83e009e05', usage_metadata={'input_tokens': 408, 'output_tokens': 18, 'total_tokens': 426, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}, 'run_id': '1c7ceaa5-2f51-4847-9bf7-79012aa83a39', 'name': 'should_summarize', 'tags': ['seq:step:4'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 6, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'revision_id': 'f1ac15a-dirty'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d', '3fd6cc28-2a61-4005-880c-55283487627b']}\n",
      "{'event': 'on_chain_stream', 'run_id': '3fd6cc28-2a61-4005-880c-55283487627b', 'name': 'call_llm', 'tags': ['graph:step:6'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 6, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a'}, 'data': {'chunk': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': \"Tomorrow's date is 2025-11-03.\\n\", 'messages': [HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content=\"Tomorrow's date is 2025-11-03.\\n\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bd25b2c7-63f3-440e-8308-b7a83e009e05', usage_metadata={'input_tokens': 408, 'output_tokens': 18, 'total_tokens': 426, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d']}\n",
      "{'event': 'on_chain_end', 'data': {'output': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': \"Tomorrow's date is 2025-11-03.\\n\", 'messages': [HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content=\"Tomorrow's date is 2025-11-03.\\n\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bd25b2c7-63f3-440e-8308-b7a83e009e05', usage_metadata={'input_tokens': 408, 'output_tokens': 18, 'total_tokens': 426, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}, 'input': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': '', 'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), ToolMessage(content='Date: 2025-11-02\\n\\nTime: 20:08:19.141281 (GMT+1)\\n\\nDay Name: Sunday', name='date_and_time_tool', id='16485e18-ce47-4dba-8607-5927ac9978fb', tool_call_id='tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13')], 'summary': ''}}, 'run_id': '3fd6cc28-2a61-4005-880c-55283487627b', 'name': 'call_llm', 'tags': ['graph:step:6'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 6, 'langgraph_node': 'call_llm', 'langgraph_triggers': ('branch:to:call_llm',), 'langgraph_path': ('__pregel_pull', 'call_llm'), 'langgraph_checkpoint_ns': 'call_llm:2bfcecad-43c5-316e-ed71-edb50bf38c3a', 'revision_id': 'f1ac15a-dirty'}, 'parent_ids': ['edc494b8-b139-4049-8cd1-297cfd47bb7d']}\n",
      "{'event': 'on_chain_stream', 'run_id': 'edc494b8-b139-4049-8cd1-297cfd47bb7d', 'name': 'LangGraph', 'tags': [], 'metadata': {'thread_id': 'test-02', 'revision_id': 'f1ac15a-dirty'}, 'data': {'chunk': {'call_llm': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': \"Tomorrow's date is 2025-11-03.\\n\", 'messages': [HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content=\"Tomorrow's date is 2025-11-03.\\n\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bd25b2c7-63f3-440e-8308-b7a83e009e05', usage_metadata={'input_tokens': 408, 'output_tokens': 18, 'total_tokens': 426, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}}, 'parent_ids': []}\n",
      "{'event': 'on_chain_end', 'data': {'output': {'query': HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), 'answer': \"Tomorrow's date is 2025-11-03.\\n\", 'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}, id='6108074c-b651-45b4-9c7b-4d13800418db'), AIMessage(content='Hello neidu, how can I help you today?\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 276, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'google/gemini-2.0-flash-001', 'system_fingerprint': None, 'id': 'gen-1762110454-IPY2NJLboGeEefEv6n7P', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--925c3788-c3a2-41f7-9d66-2992a06e76f5-0', usage_metadata={'input_tokens': 276, 'output_tokens': 12, 'total_tokens': 288, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), HumanMessage(content=\"What is tomorrow's date?\", additional_kwargs={}, response_metadata={}, id='a0c182be-410c-4d98-bcf0-22c3dab717fb'), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bc4e517b-2775-4f83-8eae-84f532d1b235', tool_calls=[{'name': 'date_and_time_tool', 'args': {}, 'id': 'tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 7, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}), ToolMessage(content='Date: 2025-11-02\\n\\nTime: 20:08:19.141281 (GMT+1)\\n\\nDay Name: Sunday', name='date_and_time_tool', id='16485e18-ce47-4dba-8607-5927ac9978fb', tool_call_id='tool_0_date_and_time_tool_VThszOTJjVBiIUPQia13'), AIMessage(content=\"Tomorrow's date is 2025-11-03.\\n\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'google/gemini-2.0-flash-001', 'model_provider': 'openai'}, id='lc_run--bd25b2c7-63f3-440e-8308-b7a83e009e05', usage_metadata={'input_tokens': 408, 'output_tokens': 18, 'total_tokens': 426, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})], 'summary': ''}}, 'run_id': 'edc494b8-b139-4049-8cd1-297cfd47bb7d', 'name': 'LangGraph', 'tags': [], 'metadata': {'thread_id': 'test-02', 'revision_id': 'f1ac15a-dirty'}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "# Generate real-time events. This can be used to stream events to the UI\n",
    "# The model starts responding when the event is `on_chat_model_stream` and stops at `on_chat_model_end`\n",
    "response = graph.astream_events(\n",
    "    {\"query\": HumanMessage(\"What is tomorrow's date?\")},\n",
    "    config=config,  # type: ignore\n",
    "    version=\"v2\",\n",
    ")\n",
    "\n",
    "async for chunk in response:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate real-time events\n",
    "response = graph.astream_events(\n",
    "    {\"query\": HumanMessage(\"Please verify that for me.\")},\n",
    "    config=config,  # type: ignore\n",
    "    version=\"v2\",\n",
    ")\n",
    "\n",
    "async for chunk in response:\n",
    "    if chunk.get(\"event\") == \"on_chat_model_end\":\n",
    "        print(chunk.get(\"data\").get(\"output\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58490408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate real-time events. This can be used to stream events to the UI\n",
    "# The model starts responding when the event is `on_chat_model_stream` and stops at `on_chat_model_end`\n",
    "response = graph.astream_events(\n",
    "    {\"query\": HumanMessage(\"Why is the earth round?\")},\n",
    "    config=config,  # type: ignore\n",
    "    version=\"v2\",\n",
    ")\n",
    "\n",
    "async for chunk in response:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2aac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d50f95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35c47a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart-rag (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
