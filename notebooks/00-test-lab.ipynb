{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7cad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "from typing import Any, Literal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"white\": \"#FFFFFF\",  # Bright white\n",
    "        \"info\": \"#00FF00\",  # Bright green\n",
    "        \"warning\": \"#FFD700\",  # Bright gold\n",
    "        \"error\": \"#FF1493\",  # Deep pink\n",
    "        \"success\": \"#00FFFF\",  # Cyan\n",
    "        \"highlight\": \"#FF4500\",  # Orange-red\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# NumPy settings\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Polars settings\n",
    "pl.Config.set_fmt_str_lengths(1_000)\n",
    "pl.Config.set_tbl_cols(n=1_000)\n",
    "pl.Config.set_tbl_rows(n=200)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba7e078f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Smart-RAG', 'version': '1.0'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def go_up_from_current_directory(*, go_up: int = 1) -> None:\n",
    "    \"\"\"This is used to up a number of directories.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    go_up: int, default=1\n",
    "        This indicates the number of times to go back up from the current directory.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    CONST: str = \"../\"\n",
    "    NUM: str = CONST * go_up\n",
    "\n",
    "    # Goto the previous directory\n",
    "    prev_directory = os.path.join(os.path.dirname(__name__), NUM)\n",
    "    # Get the 'absolute path' of the previous directory\n",
    "    abs_path_prev_directory = os.path.abspath(prev_directory)\n",
    "\n",
    "    # Add the path to the System paths\n",
    "    sys.path.insert(0, abs_path_prev_directory)\n",
    "    print(abs_path_prev_directory)\n",
    "\n",
    "\n",
    "# Demo (Prevents ruff from removing the unused module import)\n",
    "name: Any\n",
    "category: Literal[\"A\", \"B\", \"C\"]\n",
    "json.loads('{\"name\": \"Smart-RAG\", \"version\": \"1.0\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da164420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mac/Desktop/Projects/smart-rag\n"
     ]
    }
   ],
   "source": [
    "go_up_from_current_directory(go_up=1)\n",
    "\n",
    "from src.config import app_settings  # noqa: E402\n",
    "from src.utilities.model_config import RemoteModel  # noqa: E402\n",
    "\n",
    "settings = app_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec396d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "527e9ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "remote_llm = ChatOpenAI(\n",
    "    api_key=settings.OPENROUTER_API_KEY.get_secret_value(),  # type: ignore\n",
    "    base_url=settings.OPENROUTER_URL,\n",
    "    temperature=0.0,\n",
    "    model=RemoteModel.GEMINI_2_0_FLASH_001,\n",
    ")\n",
    "\n",
    "\n",
    "# Test the LLMs\n",
    "response = remote_llm.invoke(\"Tell me a very short joke.\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593ca6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c54bd3",
   "metadata": {},
   "source": [
    "#### Create Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24c9f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tavily_search = TavilySearch(\n",
    "    api_key=settings.TAVILY_API_KEY.get_secret_value(),\n",
    "    max_results=2,\n",
    "    topic=\"general\",\n",
    ")\n",
    "search_response = tavily_search.invoke({\"query\": \"What is agentic RAG?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c80e1d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'* Agentic RAG # Agentic RAG Agentic RAG is a standard RAG implementation that uses AI agents to solve complex problems by extending the capabilities of LLMs. A classical RAG approach relies solely on LLMs. The agentic RAG method converts LLMs into AI agents and empowers them to use tools, functions, and external knowledge sources. * A RAG agent customer support system can help users find specific information from unstructured, semi-unstructured, and structured data formats. * Agent-powered RAG systems are excellent at looking at and retrieving information from heterogeneous enterprise data. In contrast, an agentic RAG system is capable of retrieving and synthesizing information from multiple sources and documents. A classic RAG can retrieve information from a single source, while an agentic RAG uses multiple agents to access and orchestrate data from diverse sources.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_response[\"results\"][0][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c0d1428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is agentic RAG?',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://getstream.io/glossary/agentic-rag/',\n",
       "   'title': 'Agentic RAG - What is it and how does it work? - GetStream.io',\n",
       "   'content': '* Agentic RAG # Agentic RAG Agentic RAG is a standard RAG implementation that uses AI agents to solve complex problems by extending the capabilities of LLMs. A classical RAG approach relies solely on LLMs. The agentic RAG method converts LLMs into AI agents and empowers them to use tools, functions, and external knowledge sources. * A RAG agent customer support system can help users find specific information from unstructured, semi-unstructured, and structured data formats. * Agent-powered RAG systems are excellent at looking at and retrieving information from heterogeneous enterprise data. In contrast, an agentic RAG system is capable of retrieving and synthesizing information from multiple sources and documents. A classic RAG can retrieve information from a single source, while an agentic RAG uses multiple agents to access and orchestrate data from diverse sources.',\n",
       "   'score': 0.95176035,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.ibm.com/think/topics/agentic-rag',\n",
       "   'title': 'What is Agentic RAG? | IBM',\n",
       "   'content': '# What is agentic RAG? Agentic RAG is the use of AI agents to facilitate retrieval augmented generation (RAG). Agentic RAG systems add AI agents to the RAG pipeline to increase adaptability and accuracy. ### What is agentic AI? AI agents ### What are AI agents? From monolithic models to compound AI systems, discover how AI agents integrate with databases and external tools to enhance problem-solving capabilities and adaptability. ## How does agentic RAG work? Agentic RAG works by incorporating one or more types of AI agents into RAG systems. Agentic RAG systems can contain one or more types of AI agents, such as: Report   Agentic AI products to watch out for in 2025  AI agents for business    IBM AI agent solutions    Explore AI agent solutions   ',\n",
       "   'score': 0.9465623,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 1.14,\n",
       " 'request_id': '3e8f4e34-c9a1-4c59-bcd4-045dcfbc59c5'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65b50b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "async def search_tool(query: str, max_chars: int = 500) -> tuple[str, dict]:\n",
    "    \"\"\"Perform a search using TavilySearch tool.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    query: str\n",
    "        The search query.\n",
    "    max_chars: int, default=1000\n",
    "        The maximum number of characters per source to return from the search results.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        The formatted search results.\n",
    "    \"\"\"\n",
    "    separator: str = \"\\n\\n\"\n",
    "\n",
    "    tavily_search = TavilySearch(\n",
    "        api_key=settings.TAVILY_API_KEY.get_secret_value(),\n",
    "        max_results=3,\n",
    "        topic=\"general\",\n",
    "    )\n",
    "    search_response = await tavily_search.ainvoke({\"query\": query})\n",
    "    formatted_results: str = \"\\n\\n\".join(\n",
    "        f\"Title: {result['title']}\\nContent: {result['content'][:max_chars]} [truncated]\\nURL: {result['url']}{separator}\"\n",
    "        for result in search_response[\"results\"]\n",
    "    )\n",
    "    return formatted_results, search_response\n",
    "\n",
    "\n",
    "@tool(response_format=\"content\")\n",
    "def date_tool() -> str:\n",
    "    \"\"\"Get the current date in YYYY-MM-DD format.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        The current date as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    return datetime.now().isoformat(timespec=\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8569c7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">StructuredTool</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'search_tool'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">description</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Perform a search using TavilySearch tool.\\n\\n    Parameters:\\n    -----------\\n    query: str\\n   </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The search query.\\n    max_chars: int, default=1000\\n        The maximum number of characters per source to return </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from the search results.\\n\\n    Returns:\\n    --------\\n    str\\n        The formatted search results.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">args_schema</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'langchain_core.utils.pydantic.search_tool'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">response_format</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'content_and_artifact'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">coroutine</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;function search_tool at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x13c792f20</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mStructuredTool\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mname\u001b[0m=\u001b[32m'search_tool'\u001b[0m,\n",
       "    \u001b[33mdescription\u001b[0m=\u001b[32m'Perform a search using TavilySearch tool.\\n\\n    Parameters:\\n    -----------\\n    query: str\\n   \u001b[0m\n",
       "\u001b[32mThe search query.\\n    max_chars: int, \u001b[0m\u001b[32mdefault\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1000\u001b[0m\u001b[32m\\n        The maximum number of characters per source to return \u001b[0m\n",
       "\u001b[32mfrom the search results.\\n\\n    Returns:\\n    --------\\n    str\\n        The formatted search results.'\u001b[0m,\n",
       "    \u001b[33margs_schema\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'langchain_core.utils.pydantic.search_tool'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mresponse_format\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'content_and_artifact'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mcoroutine\u001b[0m\u001b[39m=<function search_tool at \u001b[0m\u001b[1;36m0x13c792f20\u001b[0m\u001b[1m>\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(search_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "379a9cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Title: Agentic RAG - What is it and how does it work? - GetStream.io\n",
       "Content: * Agentic RAG # Agentic RAG Agentic RAG is a standard RAG implementation that uses AI agents to solve \n",
       "complex problems by extending the capabilities of LLMs. A classical RAG approach relies solely on LLMs. The agentic\n",
       "RAG method converts LLMs into AI agents and empowers them to use tools, functions, and external knowledge sources. \n",
       "* A RAG agent customer support system can help users find specific information from unstructured, \n",
       "semi-unstructured, and structured data formats. * Agent-powered RAG s \n",
       "URL: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://getstream.io/glossary/agentic-rag/</span>\n",
       "\n",
       "\n",
       "\n",
       "Title: What is Agentic RAG? | IBM\n",
       "Content: # What is agentic RAG? Agentic RAG is the use of AI agents to facilitate retrieval augmented generation \n",
       "<span style=\"font-weight: bold\">(</span>RAG<span style=\"font-weight: bold\">)</span>. Agentic RAG systems add AI agents to the RAG pipeline to increase adaptability and accuracy. ### What is \n",
       "agentic AI? AI agents ### What are AI agents? From monolithic models to compound AI systems, discover how AI agents\n",
       "integrate with databases and external tools to enhance problem-solving capabilities and adaptability. ## How does \n",
       "agentic RAG work? Agentic RAG works by incorporating o \n",
       "URL: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.ibm.com/think/topics/agentic-rag</span>\n",
       "\n",
       "\n",
       "\n",
       "Title: Agentic RAG: How It Works, Use Cases, Comparison With RAG\n",
       "Content: Learn about Agentic RAG, an AI paradigm combining agentic AI and RAG for autonomous information access and\n",
       "generation. Agentic RAG combines agentic AI’s decision-making with RAG’s ability to pull in dynamic data. By \n",
       "continuously analyzing the context and user intent, agentic RAG systems can autonomously retrieve and integrate \n",
       "relevant information from diverse sources, including real-time data streams and external APIs. This proactive \n",
       "approach enables them to generate comprehensive and contextual \n",
       "URL: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.datacamp.com/blog/agentic-rag</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Title: Agentic RAG - What is it and how does it work? - GetStream.io\n",
       "Content: * Agentic RAG # Agentic RAG Agentic RAG is a standard RAG implementation that uses AI agents to solve \n",
       "complex problems by extending the capabilities of LLMs. A classical RAG approach relies solely on LLMs. The agentic\n",
       "RAG method converts LLMs into AI agents and empowers them to use tools, functions, and external knowledge sources. \n",
       "* A RAG agent customer support system can help users find specific information from unstructured, \n",
       "semi-unstructured, and structured data formats. * Agent-powered RAG s \n",
       "URL: \u001b[4;94mhttps://getstream.io/glossary/agentic-rag/\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "Title: What is Agentic RAG? | IBM\n",
       "Content: # What is agentic RAG? Agentic RAG is the use of AI agents to facilitate retrieval augmented generation \n",
       "\u001b[1m(\u001b[0mRAG\u001b[1m)\u001b[0m. Agentic RAG systems add AI agents to the RAG pipeline to increase adaptability and accuracy. ### What is \n",
       "agentic AI? AI agents ### What are AI agents? From monolithic models to compound AI systems, discover how AI agents\n",
       "integrate with databases and external tools to enhance problem-solving capabilities and adaptability. ## How does \n",
       "agentic RAG work? Agentic RAG works by incorporating o \n",
       "URL: \u001b[4;94mhttps://www.ibm.com/think/topics/agentic-rag\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "Title: Agentic RAG: How It Works, Use Cases, Comparison With RAG\n",
       "Content: Learn about Agentic RAG, an AI paradigm combining agentic AI and RAG for autonomous information access and\n",
       "generation. Agentic RAG combines agentic AI’s decision-making with RAG’s ability to pull in dynamic data. By \n",
       "continuously analyzing the context and user intent, agentic RAG systems can autonomously retrieve and integrate \n",
       "relevant information from diverse sources, including real-time data streams and external APIs. This proactive \n",
       "approach enables them to generate comprehensive and contextual \n",
       "URL: \u001b[4;94mhttps://www.datacamp.com/blog/agentic-rag\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "formatted_results, search_response = await search_tool.coroutine(\"what is agentic RAG?\")\n",
    "console.print(formatted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93680cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'query'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'what is agentic RAG?'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'follow_up_questions'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'images'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'results'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://getstream.io/glossary/agentic-rag/'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Agentic RAG - What is it and how does it work? - GetStream.io'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'* Agentic RAG # Agentic RAG Agentic RAG is a standard RAG implementation that uses AI </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents to solve complex problems by extending the capabilities of LLMs. A classical RAG approach relies solely on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLMs. The agentic RAG method converts LLMs into AI agents and empowers them to use tools, functions, and external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge sources. * A RAG agent customer support system can help users find specific information from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">unstructured, semi-unstructured, and structured data formats. * Agent-powered RAG systems are excellent at looking </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">at and retrieving information from heterogeneous enterprise data. In contrast, an agentic RAG system is capable of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retrieving and synthesizing information from multiple sources and documents. A classic RAG can retrieve information</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from a single source, while an agentic RAG uses multiple agents to access and orchestrate data from diverse </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sources.'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9451216</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'raw_content'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://www.ibm.com/think/topics/agentic-rag'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'What is Agentic RAG? | IBM'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'# What is agentic RAG? Agentic RAG is the use of AI agents to facilitate retrieval </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">augmented generation (RAG). Agentic RAG systems add AI agents to the RAG pipeline to increase adaptability and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">accuracy. ### What is agentic AI? AI agents ### What are AI agents? From monolithic models to compound AI systems, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">discover how AI agents integrate with databases and external tools to enhance problem-solving capabilities and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">adaptability. ## How does agentic RAG work? Agentic RAG works by incorporating one or more types of AI agents into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RAG systems. Agentic RAG systems can contain one or more types of AI agents, such as: Report   Agentic AI products </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to watch out for in 2025  AI agents for business    IBM AI agent solutions    Explore AI agent solutions   '</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9393874</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'raw_content'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://www.datacamp.com/blog/agentic-rag'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Agentic RAG: How It Works, Use Cases, Comparison With RAG'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Learn about Agentic RAG, an AI paradigm combining agentic AI and RAG for autonomous </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information access and generation. Agentic RAG combines agentic AI’s decision-making with RAG’s ability to pull in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dynamic data. By continuously analyzing the context and user intent, agentic RAG systems can autonomously retrieve </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and integrate relevant information from diverse sources, including real-time data streams and external APIs. This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">proactive approach enables them to generate comprehensive and contextually relevant responses without requiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">explicit human intervention. Agentic RAG combines the autonomy of agentic systems with the dynamic data retrieval </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of RAG. Learn how to use n8n to build AI agents that automate email processing and create a retrieval-augmented </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generation (RAG) agent for document question answering.'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9197076</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'raw_content'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'response_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.82</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'request_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'6248433c-8358-4c24-9459-934bb024bcd4'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'query'\u001b[0m: \u001b[32m'what is agentic RAG?'\u001b[0m,\n",
       "    \u001b[32m'follow_up_questions'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'answer'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'images'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'results'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'url'\u001b[0m: \u001b[32m'https://getstream.io/glossary/agentic-rag/'\u001b[0m,\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'Agentic RAG - What is it and how does it work? - GetStream.io'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m'* Agentic RAG # Agentic RAG Agentic RAG is a standard RAG implementation that uses AI \u001b[0m\n",
       "\u001b[32magents to solve complex problems by extending the capabilities of LLMs. A classical RAG approach relies solely on \u001b[0m\n",
       "\u001b[32mLLMs. The agentic RAG method converts LLMs into AI agents and empowers them to use tools, functions, and external \u001b[0m\n",
       "\u001b[32mknowledge sources. * A RAG agent customer support system can help users find specific information from \u001b[0m\n",
       "\u001b[32munstructured, semi-unstructured, and structured data formats. * Agent-powered RAG systems are excellent at looking \u001b[0m\n",
       "\u001b[32mat and retrieving information from heterogeneous enterprise data. In contrast, an agentic RAG system is capable of \u001b[0m\n",
       "\u001b[32mretrieving and synthesizing information from multiple sources and documents. A classic RAG can retrieve information\u001b[0m\n",
       "\u001b[32mfrom a single source, while an agentic RAG uses multiple agents to access and orchestrate data from diverse \u001b[0m\n",
       "\u001b[32msources.'\u001b[0m,\n",
       "            \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9451216\u001b[0m,\n",
       "            \u001b[32m'raw_content'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'url'\u001b[0m: \u001b[32m'https://www.ibm.com/think/topics/agentic-rag'\u001b[0m,\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'What is Agentic RAG? | IBM'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m'# What is agentic RAG? Agentic RAG is the use of AI agents to facilitate retrieval \u001b[0m\n",
       "\u001b[32maugmented generation \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRAG\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Agentic RAG systems add AI agents to the RAG pipeline to increase adaptability and \u001b[0m\n",
       "\u001b[32maccuracy. ### What is agentic AI? AI agents ### What are AI agents? From monolithic models to compound AI systems, \u001b[0m\n",
       "\u001b[32mdiscover how AI agents integrate with databases and external tools to enhance problem-solving capabilities and \u001b[0m\n",
       "\u001b[32madaptability. ## How does agentic RAG work? Agentic RAG works by incorporating one or more types of AI agents into \u001b[0m\n",
       "\u001b[32mRAG systems. Agentic RAG systems can contain one or more types of AI agents, such as: Report   Agentic AI products \u001b[0m\n",
       "\u001b[32mto watch out for in 2025  AI agents for business    IBM AI agent solutions    Explore AI agent solutions   '\u001b[0m,\n",
       "            \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9393874\u001b[0m,\n",
       "            \u001b[32m'raw_content'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'url'\u001b[0m: \u001b[32m'https://www.datacamp.com/blog/agentic-rag'\u001b[0m,\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'Agentic RAG: How It Works, Use Cases, Comparison With RAG'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m'Learn about Agentic RAG, an AI paradigm combining agentic AI and RAG for autonomous \u001b[0m\n",
       "\u001b[32minformation access and generation. Agentic RAG combines agentic AI’s decision-making with RAG’s ability to pull in \u001b[0m\n",
       "\u001b[32mdynamic data. By continuously analyzing the context and user intent, agentic RAG systems can autonomously retrieve \u001b[0m\n",
       "\u001b[32mand integrate relevant information from diverse sources, including real-time data streams and external APIs. This \u001b[0m\n",
       "\u001b[32mproactive approach enables them to generate comprehensive and contextually relevant responses without requiring \u001b[0m\n",
       "\u001b[32mexplicit human intervention. Agentic RAG combines the autonomy of agentic systems with the dynamic data retrieval \u001b[0m\n",
       "\u001b[32mof RAG. Learn how to use n8n to build AI agents that automate email processing and create a retrieval-augmented \u001b[0m\n",
       "\u001b[32mgeneration \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRAG\u001b[0m\u001b[32m)\u001b[0m\u001b[32m agent for document question answering.'\u001b[0m,\n",
       "            \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9197076\u001b[0m,\n",
       "            \u001b[32m'raw_content'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'response_time'\u001b[0m: \u001b[1;36m0.82\u001b[0m,\n",
       "    \u001b[32m'request_id'\u001b[0m: \u001b[32m'6248433c-8358-4c24-9459-934bb024bcd4'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print(search_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f70973b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-10-26T02:57:40'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_tool.func()\n",
    "\n",
    "# console.print(date_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "505711da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator as op\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[Any], op.add]\n",
    "\n",
    "\n",
    "async def llm_call_node(state: State) -> dict[str, Any]:\n",
    "    messages = state[\"messages\"]\n",
    "    llm_with_tools = remote_llm.bind_tools([date_tool, search_tool])\n",
    "    response = await llm_with_tools.ainvoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def end_conversation_node(state: State) -> dict[str, Any]:\n",
    "    msg: str = AIMessage(\"Than you for your time. Goodbye!\")\n",
    "    return {\"messages\": [msg]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bf20be",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Define Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a78f70da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore_football.as_retriever(search_kwargs={\"k\": 5}).invoke(\"Any news about Caicedo's contract situation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fbed307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.types import RetryPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18913adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langgraph.prebuilt import ToolNode, tools_condition\n",
    "# from langgraph.types import RetryPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23a39830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "builder: StateGraph = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "tool_node = ToolNode([date_tool, search_tool])\n",
    "\n",
    "builder.add_node(\n",
    "    \"llm_call\",\n",
    "    llm_call_node,\n",
    "    retry_policy=RetryPolicy(max_attempts=3, initial_interval=1.0),\n",
    ")\n",
    "builder.add_node(\n",
    "    \"tools\", tool_node, retry_policy=RetryPolicy(max_attempts=3, initial_interval=1.0)\n",
    ")\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"llm_call\")\n",
    "builder.add_conditional_edges(\"llm_call\", tools_condition, {\"tools\": \"tools\", END: END})\n",
    "builder.add_edge(\"tools\", \"llm_call\")\n",
    "\n",
    "# Compile the graph\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "# Visualize the graph with ASCII fallback\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    console.print(f\"[yellow]PNG visualization failed: {e}[/yellow]\")\n",
    "    console.print(\"[cyan]Displaying ASCII representation instead:[/cyan]\\n\")\n",
    "    try:\n",
    "        print(graph.get_graph(xray=1).draw_ascii())\n",
    "    except ImportError as ie:\n",
    "        console.print(f\"[red]ASCII visualization also failed: {ie}[/red]\")\n",
    "        console.print(\"[magenta]Showing basic graph structure:[/magenta]\\n\")\n",
    "        graph_obj = graph.get_graph(xray=1)\n",
    "        console.print(f\"Nodes: {[node.id for node in graph_obj.nodes.values()]}\")\n",
    "        console.print(f\"Edges: {[(e.source, e.target) for e in graph_obj.edges]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3d13ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Why don’t skeletons fight each other? They don’t have the guts.\n"
     ]
    }
   ],
   "source": [
    "remote_llm = ChatOpenAI(\n",
    "    api_key=settings.OPENROUTER_API_KEY.get_secret_value(),  # type: ignore\n",
    "    base_url=settings.OPENROUTER_URL,\n",
    "    temperature=0.0,\n",
    "    model=RemoteModel.GPT_OSS_20B,\n",
    ")\n",
    "\n",
    "\n",
    "# Test the LLMs\n",
    "response = remote_llm.invoke(\"Tell me a very short joke.\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "089bd7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, I'm neidu\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Neidu! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# Re-build the graph\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "config: dict[str, Any] = {\"configurable\": {\"thread_id\": \"test-01\"}}\n",
    "response = await graph.ainvoke(\n",
    "    {\"messages\": [HumanMessage(\"Hello, I'm neidu\")]},\n",
    "    config=config,  # type: ignore\n",
    ")\n",
    "\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1572f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, I'm neidu\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Neidu! How can I help you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is today's date?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  date_tool (functions.date_tool_c30d)\n",
      " Call ID: functions.date_tool_c30d\n",
      "  Args:\n",
      "    :\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: date_tool\n",
      "\n",
      "2025-10-26T02:59:07\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Today's date is **2025‑10‑26**.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is today's date and time?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Today’s date and time is **2025‑10‑26 02:59:07** (UTC).\n"
     ]
    }
   ],
   "source": [
    "msg: str = \"What is today's date and time?\"\n",
    "response = await graph.ainvoke({\"messages\": [HumanMessage(msg)]}, config=config)\n",
    "\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27050883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, I'm neidu\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Neidu! How can I help you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is today's date?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  date_tool (functions.date_tool_c30d)\n",
      " Call ID: functions.date_tool_c30d\n",
      "  Args:\n",
      "    :\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: date_tool\n",
      "\n",
      "2025-10-26T02:59:07\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Today's date is **2025‑10‑26**.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is today's date and time?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Today’s date and time is **2025‑10‑26 02:59:07** (UTC).\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you tell me a joke?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure thing! Why don’t programmers ever get lost in the forest?\n",
      "\n",
      "Because they always “debug” the trail! 😄\n"
     ]
    }
   ],
   "source": [
    "msg: str = \"Can you tell me a joke?\"\n",
    "response = await graph.ainvoke({\"messages\": [HumanMessage(msg)]}, config=config)\n",
    "\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "638d3804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, I'm neidu\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Neidu! How can I help you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is today's date?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  date_tool (functions.date_tool_c30d)\n",
      " Call ID: functions.date_tool_c30d\n",
      "  Args:\n",
      "    :\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: date_tool\n",
      "\n",
      "2025-10-26T02:59:07\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Today's date is **2025‑10‑26**.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is today's date and time?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Today’s date and time is **2025‑10‑26 02:59:07** (UTC).\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you tell me a joke?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure thing! Why don’t programmers ever get lost in the forest?\n",
      "\n",
      "Because they always “debug” the trail! 😄\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who won the 2002 FIFA World Cup?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The 2002 FIFA World Cup was won by **Brazil**. They defeated Germany 2–0 in the final, securing their fifth World Cup title.\n"
     ]
    }
   ],
   "source": [
    "msg: str = \"Who won the 2002 FIFA World Cup?\"\n",
    "response = await graph.ainvoke({\"messages\": [HumanMessage(msg)]}, config=config)\n",
    "\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae6c170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adce11e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "708b6df7",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1159488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={})]}\n",
      "{'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Neidu! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 233, 'total_tokens': 272, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': None, 'id': 'gen-1761444888-0BarhAMRyENUixr7hRJh', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8053fa0d-facd-4002-8b1e-94f7412d0717-0', usage_metadata={'input_tokens': 233, 'output_tokens': 39, 'total_tokens': 272, 'input_token_details': {}, 'output_token_details': {}})]}\n"
     ]
    }
   ],
   "source": [
    "# Re-build the graph\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "config: dict[str, Any] = {\"configurable\": {\"thread_id\": \"test-02\"}}\n",
    "response = graph.astream(\n",
    "    {\"messages\": [HumanMessage(\"Hello, I'm neidu\")]},\n",
    "    config=config,  # type: ignore\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "async for chunk in response:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88abb397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='Your', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' name', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' Ne', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='idu', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', chunk_position='last'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', usage_metadata={'input_tokens': 259, 'output_tokens': 42, 'total_tokens': 301, 'input_token_details': {}, 'output_token_details': {}}), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', chunk_position='last'), {'thread_id': 'test-02', 'langgraph_step': 4, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'checkpoint_ns': 'llm_call:ee91b419-a8c1-12aa-8b3a-89422f18d789', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n"
     ]
    }
   ],
   "source": [
    "response = graph.astream(\n",
    "    {\"messages\": [HumanMessage(\"What's my name?\")]},\n",
    "    config=config,  # type: ignore\n",
    "    stream_mode=\"messages\",\n",
    ")\n",
    "\n",
    "async for chunk in response:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88359ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [HumanMessage(content=\"What is today's date and time?\", additional_kwargs={}, response_metadata={})]}}, 'name': 'LangGraph', 'tags': [], 'run_id': '0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'metadata': {'thread_id': 'test-02'}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Neidu! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 233, 'total_tokens': 272, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': None, 'id': 'gen-1761444888-0BarhAMRyENUixr7hRJh', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8053fa0d-facd-4002-8b1e-94f7412d0717-0', usage_metadata={'input_tokens': 233, 'output_tokens': 39, 'total_tokens': 272, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Neidu.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', usage_metadata={'input_tokens': 259, 'output_tokens': 42, 'total_tokens': 301, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What is today's date and time?\", additional_kwargs={}, response_metadata={})]}}, 'name': 'llm_call', 'tags': ['graph:step:7'], 'run_id': 'c6695c57-7536-481d-a0a5-281829860a9e', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85'}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5']}\n",
      "{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Neidu! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 233, 'total_tokens': 272, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': None, 'id': 'gen-1761444888-0BarhAMRyENUixr7hRJh', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8053fa0d-facd-4002-8b1e-94f7412d0717-0', usage_metadata={'input_tokens': 233, 'output_tokens': 39, 'total_tokens': 272, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Neidu.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', usage_metadata={'input_tokens': 259, 'output_tokens': 42, 'total_tokens': 301, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What is today's date and time?\", additional_kwargs={}, response_metadata={})]]}}, 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e')}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e')}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e')}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e')}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e')}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e')}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e')}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e')}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e')}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e')}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e')}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e')}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e')}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e')}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', tool_calls=[{'name': 'date_tool', 'args': {'': ''}, 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'date_tool', 'args': '{\"\":\"\"}', 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'index': 0, 'type': 'tool_call_chunk'}])}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', chunk_position='last')}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', usage_metadata={'input_tokens': 293, 'output_tokens': 36, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {'reasoning': 14}})}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', chunk_position='last')}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chat_model_end', 'data': {'output': AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', tool_calls=[{'name': 'date_tool', 'args': {'': ''}, 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 36, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {'reasoning': 14}}), 'input': {'messages': [[HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Neidu! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 233, 'total_tokens': 272, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': None, 'id': 'gen-1761444888-0BarhAMRyENUixr7hRJh', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8053fa0d-facd-4002-8b1e-94f7412d0717-0', usage_metadata={'input_tokens': 233, 'output_tokens': 39, 'total_tokens': 272, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Neidu.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', usage_metadata={'input_tokens': 259, 'output_tokens': 42, 'total_tokens': 301, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What is today's date and time?\", additional_kwargs={}, response_metadata={})]]}}, 'run_id': '7d1bac36-a932-4c2e-8b39-03dfa010f04e', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'revision_id': 'ae3dd81-dirty'}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Neidu! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 233, 'total_tokens': 272, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': None, 'id': 'gen-1761444888-0BarhAMRyENUixr7hRJh', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8053fa0d-facd-4002-8b1e-94f7412d0717-0', usage_metadata={'input_tokens': 233, 'output_tokens': 39, 'total_tokens': 272, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Neidu.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', usage_metadata={'input_tokens': 259, 'output_tokens': 42, 'total_tokens': 301, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What is today's date and time?\", additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', tool_calls=[{'name': 'date_tool', 'args': {'': ''}, 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 36, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {'reasoning': 14}})]}}, 'name': 'tools_condition', 'tags': ['seq:step:3'], 'run_id': '1321d584-ca30-4e6b-a298-07bdd15159d7', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85'}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chain_end', 'data': {'output': 'tools', 'input': {'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Neidu! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 233, 'total_tokens': 272, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': None, 'id': 'gen-1761444888-0BarhAMRyENUixr7hRJh', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8053fa0d-facd-4002-8b1e-94f7412d0717-0', usage_metadata={'input_tokens': 233, 'output_tokens': 39, 'total_tokens': 272, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Neidu.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', usage_metadata={'input_tokens': 259, 'output_tokens': 42, 'total_tokens': 301, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What is today's date and time?\", additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', tool_calls=[{'name': 'date_tool', 'args': {'': ''}, 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 36, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {'reasoning': 14}})]}}, 'run_id': '1321d584-ca30-4e6b-a298-07bdd15159d7', 'name': 'tools_condition', 'tags': ['seq:step:3'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'revision_id': 'ae3dd81-dirty'}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'c6695c57-7536-481d-a0a5-281829860a9e']}\n",
      "{'event': 'on_chain_stream', 'run_id': 'c6695c57-7536-481d-a0a5-281829860a9e', 'name': 'llm_call', 'tags': ['graph:step:7'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85'}, 'data': {'chunk': {'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', tool_calls=[{'name': 'date_tool', 'args': {'': ''}, 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 36, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {'reasoning': 14}})]}}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5']}\n",
      "{'event': 'on_chain_end', 'data': {'output': {'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', tool_calls=[{'name': 'date_tool', 'args': {'': ''}, 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 36, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {'reasoning': 14}})]}, 'input': {'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Neidu! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 233, 'total_tokens': 272, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': None, 'id': 'gen-1761444888-0BarhAMRyENUixr7hRJh', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8053fa0d-facd-4002-8b1e-94f7412d0717-0', usage_metadata={'input_tokens': 233, 'output_tokens': 39, 'total_tokens': 272, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Neidu.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', usage_metadata={'input_tokens': 259, 'output_tokens': 42, 'total_tokens': 301, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What is today's date and time?\", additional_kwargs={}, response_metadata={})]}}, 'run_id': 'c6695c57-7536-481d-a0a5-281829860a9e', 'name': 'llm_call', 'tags': ['graph:step:7'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 7, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:684e2523-e7bc-9366-8b3c-9816ffd25a85', 'revision_id': 'ae3dd81-dirty'}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5']}\n",
      "{'event': 'on_chain_stream', 'run_id': '0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'name': 'LangGraph', 'tags': [], 'metadata': {'thread_id': 'test-02'}, 'data': {'chunk': {'llm_call': {'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', tool_calls=[{'name': 'date_tool', 'args': {'': ''}, 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 36, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {'reasoning': 14}})]}}}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Neidu! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 233, 'total_tokens': 272, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': None, 'id': 'gen-1761444888-0BarhAMRyENUixr7hRJh', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8053fa0d-facd-4002-8b1e-94f7412d0717-0', usage_metadata={'input_tokens': 233, 'output_tokens': 39, 'total_tokens': 272, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Neidu.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', usage_metadata={'input_tokens': 259, 'output_tokens': 42, 'total_tokens': 301, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What is today's date and time?\", additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', tool_calls=[{'name': 'date_tool', 'args': {'': ''}, 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 36, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {'reasoning': 14}})]}}, 'name': 'tools', 'tags': ['graph:step:8'], 'run_id': '30c5faef-4ff3-4f29-ae27-ba6a0037e91d', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 8, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'tools:79171bf3-9808-6baf-0983-08c575d9721a'}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5']}\n",
      "{'event': 'on_tool_start', 'data': {'input': {'': ''}}, 'name': 'date_tool', 'tags': ['seq:step:1'], 'run_id': '00823bfa-dcc7-4f4a-a56d-27d3f9cdcad9', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 8, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'tools:79171bf3-9808-6baf-0983-08c575d9721a', 'checkpoint_ns': 'tools:79171bf3-9808-6baf-0983-08c575d9721a'}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '30c5faef-4ff3-4f29-ae27-ba6a0037e91d']}\n",
      "{'event': 'on_tool_end', 'data': {'output': ToolMessage(content='2025-10-26T03:14:54', name='date_tool', tool_call_id='fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3'), 'input': {'': ''}}, 'run_id': '00823bfa-dcc7-4f4a-a56d-27d3f9cdcad9', 'name': 'date_tool', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 8, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'tools:79171bf3-9808-6baf-0983-08c575d9721a', 'checkpoint_ns': 'tools:79171bf3-9808-6baf-0983-08c575d9721a', 'revision_id': 'ae3dd81-dirty'}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '30c5faef-4ff3-4f29-ae27-ba6a0037e91d']}\n",
      "{'event': 'on_chain_stream', 'run_id': '30c5faef-4ff3-4f29-ae27-ba6a0037e91d', 'name': 'tools', 'tags': ['graph:step:8'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 8, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'tools:79171bf3-9808-6baf-0983-08c575d9721a'}, 'data': {'chunk': {'messages': [ToolMessage(content='2025-10-26T03:14:54', name='date_tool', tool_call_id='fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3')]}}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5']}\n",
      "{'event': 'on_chain_end', 'data': {'output': {'messages': [ToolMessage(content='2025-10-26T03:14:54', name='date_tool', tool_call_id='fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3')]}, 'input': {'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Neidu! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 233, 'total_tokens': 272, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': None, 'id': 'gen-1761444888-0BarhAMRyENUixr7hRJh', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8053fa0d-facd-4002-8b1e-94f7412d0717-0', usage_metadata={'input_tokens': 233, 'output_tokens': 39, 'total_tokens': 272, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Neidu.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', usage_metadata={'input_tokens': 259, 'output_tokens': 42, 'total_tokens': 301, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What is today's date and time?\", additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', tool_calls=[{'name': 'date_tool', 'args': {'': ''}, 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 36, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {'reasoning': 14}})]}}, 'run_id': '30c5faef-4ff3-4f29-ae27-ba6a0037e91d', 'name': 'tools', 'tags': ['graph:step:8'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 8, 'langgraph_node': 'tools', 'langgraph_triggers': ('branch:to:tools',), 'langgraph_path': ('__pregel_pull', 'tools'), 'langgraph_checkpoint_ns': 'tools:79171bf3-9808-6baf-0983-08c575d9721a', 'revision_id': 'ae3dd81-dirty'}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5']}\n",
      "{'event': 'on_chain_stream', 'run_id': '0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'name': 'LangGraph', 'tags': [], 'metadata': {'thread_id': 'test-02'}, 'data': {'chunk': {'tools': {'messages': [ToolMessage(content='2025-10-26T03:14:54', name='date_tool', tool_call_id='fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3')]}}}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Neidu! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 233, 'total_tokens': 272, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': None, 'id': 'gen-1761444888-0BarhAMRyENUixr7hRJh', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8053fa0d-facd-4002-8b1e-94f7412d0717-0', usage_metadata={'input_tokens': 233, 'output_tokens': 39, 'total_tokens': 272, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Neidu.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', usage_metadata={'input_tokens': 259, 'output_tokens': 42, 'total_tokens': 301, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What is today's date and time?\", additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', tool_calls=[{'name': 'date_tool', 'args': {'': ''}, 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 36, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {'reasoning': 14}}), ToolMessage(content='2025-10-26T03:14:54', name='date_tool', tool_call_id='fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3')]}}, 'name': 'llm_call', 'tags': ['graph:step:9'], 'run_id': '90bcb38e-6d64-4496-9e4a-be57da4c636f', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b'}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5']}\n",
      "{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Neidu! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 233, 'total_tokens': 272, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': None, 'id': 'gen-1761444888-0BarhAMRyENUixr7hRJh', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8053fa0d-facd-4002-8b1e-94f7412d0717-0', usage_metadata={'input_tokens': 233, 'output_tokens': 39, 'total_tokens': 272, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Neidu.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', usage_metadata={'input_tokens': 259, 'output_tokens': 42, 'total_tokens': 301, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What is today's date and time?\", additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', tool_calls=[{'name': 'date_tool', 'args': {'': ''}, 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 36, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {'reasoning': 14}}), ToolMessage(content='2025-10-26T03:14:54', name='date_tool', tool_call_id='fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3')]]}}, 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=\"Today's\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' date', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='202', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='5', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='‑', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='10', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='‑', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='26', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' current', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' time', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='03', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='14', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='\\u202f', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='UTC', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1', chunk_position='last')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1', usage_metadata={'input_tokens': 336, 'output_tokens': 27, 'total_tokens': 363, 'input_token_details': {}, 'output_token_details': {}})}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1', chunk_position='last')}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chat_model_end', 'data': {'output': AIMessage(content=\"Today's date is **2025‑10‑26**. The current time is **03:14\\u202fUTC**.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1', usage_metadata={'input_tokens': 336, 'output_tokens': 27, 'total_tokens': 363, 'input_token_details': {}, 'output_token_details': {}}), 'input': {'messages': [[HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Neidu! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 233, 'total_tokens': 272, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': None, 'id': 'gen-1761444888-0BarhAMRyENUixr7hRJh', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8053fa0d-facd-4002-8b1e-94f7412d0717-0', usage_metadata={'input_tokens': 233, 'output_tokens': 39, 'total_tokens': 272, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Neidu.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', usage_metadata={'input_tokens': 259, 'output_tokens': 42, 'total_tokens': 301, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What is today's date and time?\", additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', tool_calls=[{'name': 'date_tool', 'args': {'': ''}, 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 36, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {'reasoning': 14}}), ToolMessage(content='2025-10-26T03:14:54', name='date_tool', tool_call_id='fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3')]]}}, 'run_id': '653b2361-012f-4d05-b9b8-5a187e6957d1', 'name': 'ChatOpenAI', 'tags': ['seq:step:1'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'ls_provider': 'openai', 'ls_model_name': 'openai/gpt-oss-20b', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'revision_id': 'ae3dd81-dirty'}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Neidu! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 233, 'total_tokens': 272, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': None, 'id': 'gen-1761444888-0BarhAMRyENUixr7hRJh', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8053fa0d-facd-4002-8b1e-94f7412d0717-0', usage_metadata={'input_tokens': 233, 'output_tokens': 39, 'total_tokens': 272, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Neidu.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', usage_metadata={'input_tokens': 259, 'output_tokens': 42, 'total_tokens': 301, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What is today's date and time?\", additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', tool_calls=[{'name': 'date_tool', 'args': {'': ''}, 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 36, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {'reasoning': 14}}), ToolMessage(content='2025-10-26T03:14:54', name='date_tool', tool_call_id='fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3'), AIMessage(content=\"Today's date is **2025‑10‑26**. The current time is **03:14\\u202fUTC**.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1', usage_metadata={'input_tokens': 336, 'output_tokens': 27, 'total_tokens': 363, 'input_token_details': {}, 'output_token_details': {}})]}}, 'name': 'tools_condition', 'tags': ['seq:step:3'], 'run_id': '84f3e96b-9425-4626-b7f1-aee62b57c0ff', 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b'}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chain_end', 'data': {'output': '__end__', 'input': {'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Neidu! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 233, 'total_tokens': 272, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': None, 'id': 'gen-1761444888-0BarhAMRyENUixr7hRJh', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8053fa0d-facd-4002-8b1e-94f7412d0717-0', usage_metadata={'input_tokens': 233, 'output_tokens': 39, 'total_tokens': 272, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Neidu.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', usage_metadata={'input_tokens': 259, 'output_tokens': 42, 'total_tokens': 301, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What is today's date and time?\", additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', tool_calls=[{'name': 'date_tool', 'args': {'': ''}, 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 36, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {'reasoning': 14}}), ToolMessage(content='2025-10-26T03:14:54', name='date_tool', tool_call_id='fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3'), AIMessage(content=\"Today's date is **2025‑10‑26**. The current time is **03:14\\u202fUTC**.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1', usage_metadata={'input_tokens': 336, 'output_tokens': 27, 'total_tokens': 363, 'input_token_details': {}, 'output_token_details': {}})]}}, 'run_id': '84f3e96b-9425-4626-b7f1-aee62b57c0ff', 'name': 'tools_condition', 'tags': ['seq:step:3'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'revision_id': 'ae3dd81-dirty'}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5', '90bcb38e-6d64-4496-9e4a-be57da4c636f']}\n",
      "{'event': 'on_chain_stream', 'run_id': '90bcb38e-6d64-4496-9e4a-be57da4c636f', 'name': 'llm_call', 'tags': ['graph:step:9'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b'}, 'data': {'chunk': {'messages': [AIMessage(content=\"Today's date is **2025‑10‑26**. The current time is **03:14\\u202fUTC**.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1', usage_metadata={'input_tokens': 336, 'output_tokens': 27, 'total_tokens': 363, 'input_token_details': {}, 'output_token_details': {}})]}}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5']}\n",
      "{'event': 'on_chain_end', 'data': {'output': {'messages': [AIMessage(content=\"Today's date is **2025‑10‑26**. The current time is **03:14\\u202fUTC**.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1', usage_metadata={'input_tokens': 336, 'output_tokens': 27, 'total_tokens': 363, 'input_token_details': {}, 'output_token_details': {}})]}, 'input': {'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Neidu! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 233, 'total_tokens': 272, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': None, 'id': 'gen-1761444888-0BarhAMRyENUixr7hRJh', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8053fa0d-facd-4002-8b1e-94f7412d0717-0', usage_metadata={'input_tokens': 233, 'output_tokens': 39, 'total_tokens': 272, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Neidu.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', usage_metadata={'input_tokens': 259, 'output_tokens': 42, 'total_tokens': 301, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What is today's date and time?\", additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', tool_calls=[{'name': 'date_tool', 'args': {'': ''}, 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 36, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {'reasoning': 14}}), ToolMessage(content='2025-10-26T03:14:54', name='date_tool', tool_call_id='fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3')]}}, 'run_id': '90bcb38e-6d64-4496-9e4a-be57da4c636f', 'name': 'llm_call', 'tags': ['graph:step:9'], 'metadata': {'thread_id': 'test-02', 'langgraph_step': 9, 'langgraph_node': 'llm_call', 'langgraph_triggers': ('branch:to:llm_call',), 'langgraph_path': ('__pregel_pull', 'llm_call'), 'langgraph_checkpoint_ns': 'llm_call:9ff1c726-970d-1eb9-57b2-8657f4ceb36b', 'revision_id': 'ae3dd81-dirty'}, 'parent_ids': ['0be26deb-0d71-4518-8a3d-3c90a0aff8b5']}\n",
      "{'event': 'on_chain_stream', 'run_id': '0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'name': 'LangGraph', 'tags': [], 'metadata': {'thread_id': 'test-02', 'revision_id': 'ae3dd81-dirty'}, 'data': {'chunk': {'llm_call': {'messages': [AIMessage(content=\"Today's date is **2025‑10‑26**. The current time is **03:14\\u202fUTC**.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1', usage_metadata={'input_tokens': 336, 'output_tokens': 27, 'total_tokens': 363, 'input_token_details': {}, 'output_token_details': {}})]}}}, 'parent_ids': []}\n",
      "{'event': 'on_chain_end', 'data': {'output': {'messages': [HumanMessage(content=\"Hello, I'm neidu\", additional_kwargs={}, response_metadata={}), AIMessage(content='Hello, Neidu! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 233, 'total_tokens': 272, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': None, 'id': 'gen-1761444888-0BarhAMRyENUixr7hRJh', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8053fa0d-facd-4002-8b1e-94f7412d0717-0', usage_metadata={'input_tokens': 233, 'output_tokens': 39, 'total_tokens': 272, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Neidu.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--6afec03e-7ec2-4bf3-bb9d-641fde905dcb', usage_metadata={'input_tokens': 259, 'output_tokens': 42, 'total_tokens': 301, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"What is today's date and time?\", additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'model_provider': 'openai'}, id='lc_run--7d1bac36-a932-4c2e-8b39-03dfa010f04e', tool_calls=[{'name': 'date_tool', 'args': {'': ''}, 'id': 'fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 36, 'total_tokens': 329, 'input_token_details': {}, 'output_token_details': {'reasoning': 14}}), ToolMessage(content='2025-10-26T03:14:54', name='date_tool', tool_call_id='fc_d3ffc229-e4e9-4d7b-b55b-ed71ebbaf4c3'), AIMessage(content=\"Today's date is **2025‑10‑26**. The current time is **03:14\\u202fUTC**.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b', 'model_provider': 'openai'}, id='lc_run--653b2361-012f-4d05-b9b8-5a187e6957d1', usage_metadata={'input_tokens': 336, 'output_tokens': 27, 'total_tokens': 363, 'input_token_details': {}, 'output_token_details': {}})]}}, 'run_id': '0be26deb-0d71-4518-8a3d-3c90a0aff8b5', 'name': 'LangGraph', 'tags': [], 'metadata': {'thread_id': 'test-02', 'revision_id': 'ae3dd81-dirty'}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "# Generate real-time events. This can be used to stream events to the UI\n",
    "# The model starts responding when the event is `on_chat_model_stream` and stops at `on_chat_model_end`\n",
    "response = graph.astream_events(\n",
    "    {\"messages\": [HumanMessage(\"What is today's date and time?\")]},\n",
    "    config=config,  # type: ignore\n",
    "    version=\"v2\",\n",
    ")\n",
    "\n",
    "async for chunk in response:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate real-time events\n",
    "response = graph.astream_events(\n",
    "    {\"messages\": [HumanMessage(\"Please verify that for me.\")]},\n",
    "    config=config,  # type: ignore\n",
    "    version=\"v2\",\n",
    ")\n",
    "\n",
    "async for chunk in response:\n",
    "    if chunk.get(\"event\") == \"on_chat_model_end\":\n",
    "        print(chunk.get(\"data\").get(\"output\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58490408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate real-time events. This can be used to stream events to the UI\n",
    "# The model starts responding when the event is `on_chat_model_stream` and stops at `on_chat_model_end`\n",
    "response = graph.astream_events(\n",
    "    {\"messages\": [HumanMessage(\"Where did Peter Obi study?\")]},\n",
    "    config=config,  # type: ignore\n",
    "    version=\"v2\",\n",
    ")\n",
    "\n",
    "async for chunk in response:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e17242",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"event\": \"on_chat_model_end\",\n",
    "    \"data\": {\n",
    "        \"output\": AIMessage(\n",
    "            content=\"\",\n",
    "            additional_kwargs={},\n",
    "            response_metadata={\n",
    "                \"finish_reason\": \"tool_calls\",\n",
    "                \"model_name\": \"openai/gpt-oss-20b\",\n",
    "                \"model_provider\": \"openai\",\n",
    "            },\n",
    "            id=\"lc_run--00f6ab86-4e41-49f9-b407-b7f868de6366\",\n",
    "            tool_calls=[\n",
    "                {\n",
    "                    \"name\": \"search_tool\",\n",
    "                    \"args\": {\n",
    "                        \"query\": \"Peter Obi education where did he study\",\n",
    "                        \"max_chars\": 500,\n",
    "                    },\n",
    "                    \"id\": \"functions.search_tool_134c\",\n",
    "                    \"type\": \"tool_call\",\n",
    "                }\n",
    "            ],\n",
    "            usage_metadata={\n",
    "                \"input_tokens\": 334,\n",
    "                \"output_tokens\": 56,\n",
    "                \"total_tokens\": 390,\n",
    "                \"input_token_details\": {},\n",
    "                \"output_token_details\": {},\n",
    "            },\n",
    "        ),\n",
    "        \"input\": {\n",
    "            \"messages\": [\n",
    "                [\n",
    "                    HumanMessage(\n",
    "                        content=\"Hello, I'm neidu\",\n",
    "                        additional_kwargs={},\n",
    "                        response_metadata={},\n",
    "                    ),\n",
    "                    AIMessage(\n",
    "                        content=\"Hello Neidu! 👋 How can I help you today?\",\n",
    "                        additional_kwargs={\"refusal\": None},\n",
    "                        response_metadata={\n",
    "                            \"token_usage\": {\n",
    "                                \"completion_tokens\": 50,\n",
    "                                \"prompt_tokens\": 192,\n",
    "                                \"total_tokens\": 242,\n",
    "                                \"completion_tokens_details\": None,\n",
    "                                \"prompt_tokens_details\": None,\n",
    "                            },\n",
    "                            \"model_provider\": \"openai\",\n",
    "                            \"model_name\": \"openai/gpt-oss-20b\",\n",
    "                            \"system_fingerprint\": None,\n",
    "                            \"id\": \"gen-1761438180-BZ1Pe6JAyGcYGUc0s09C\",\n",
    "                            \"finish_reason\": \"stop\",\n",
    "                            \"logprobs\": None,\n",
    "                        },\n",
    "                        id=\"lc_run--bdd6d5c6-f7fe-49d9-b9ef-8212b73be0be-0\",\n",
    "                        usage_metadata={\n",
    "                            \"input_tokens\": 192,\n",
    "                            \"output_tokens\": 50,\n",
    "                            \"total_tokens\": 242,\n",
    "                            \"input_token_details\": {},\n",
    "                            \"output_token_details\": {},\n",
    "                        },\n",
    "                    ),\n",
    "                    HumanMessage(\n",
    "                        content=\"What's my name?\",\n",
    "                        additional_kwargs={},\n",
    "                        response_metadata={},\n",
    "                    ),\n",
    "                    AIMessage(\n",
    "                        content=\"You’re Neidu!\",\n",
    "                        additional_kwargs={},\n",
    "                        response_metadata={\n",
    "                            \"finish_reason\": \"stop\",\n",
    "                            \"model_name\": \"openai/gpt-oss-20b\",\n",
    "                            \"model_provider\": \"openai\",\n",
    "                        },\n",
    "                        id=\"lc_run--c1bdfa40-81d9-4e1e-9ae9-ff3f2877d00e\",\n",
    "                        usage_metadata={\n",
    "                            \"input_tokens\": 219,\n",
    "                            \"output_tokens\": 42,\n",
    "                            \"total_tokens\": 261,\n",
    "                            \"input_token_details\": {},\n",
    "                            \"output_token_details\": {},\n",
    "                        },\n",
    "                    ),\n",
    "                    HumanMessage(\n",
    "                        content=\"Are you sure?\",\n",
    "                        additional_kwargs={},\n",
    "                        response_metadata={},\n",
    "                    ),\n",
    "                    AIMessage(\n",
    "                        content=\"Yes—I’m remembering that you introduced yourself as “Neidu.” If that’s not correct or you’d like me to use a different name, just let me know!\",\n",
    "                        additional_kwargs={},\n",
    "                        response_metadata={\n",
    "                            \"finish_reason\": \"stop\",\n",
    "                            \"model_name\": \"openai/gpt-oss-20b\",\n",
    "                            \"system_fingerprint\": \"fp_e189667b30\",\n",
    "                            \"model_provider\": \"openai\",\n",
    "                        },\n",
    "                        id=\"lc_run--306354b6-872b-4560-a146-6e6567c35a35\",\n",
    "                        usage_metadata={\n",
    "                            \"input_tokens\": 249,\n",
    "                            \"output_tokens\": 87,\n",
    "                            \"total_tokens\": 336,\n",
    "                            \"input_token_details\": {},\n",
    "                            \"output_token_details\": {\"reasoning\": 44},\n",
    "                        },\n",
    "                    ),\n",
    "                    HumanMessage(\n",
    "                        content=\"Please verify that for me.\",\n",
    "                        additional_kwargs={},\n",
    "                        response_metadata={},\n",
    "                    ),\n",
    "                    AIMessage(\n",
    "                        content=\"I’m remembering that you introduced yourself as “Neidu.”  \\nWould you like me to confirm that’s the name you’d like me to use?\",\n",
    "                        additional_kwargs={},\n",
    "                        response_metadata={\n",
    "                            \"finish_reason\": \"stop\",\n",
    "                            \"model_name\": \"openai/gpt-oss-20b\",\n",
    "                            \"model_provider\": \"openai\",\n",
    "                        },\n",
    "                        id=\"lc_run--97e572b5-91f4-42bb-af87-1139e8ce22b4\",\n",
    "                        usage_metadata={\n",
    "                            \"input_tokens\": 288,\n",
    "                            \"output_tokens\": 146,\n",
    "                            \"total_tokens\": 434,\n",
    "                            \"input_token_details\": {},\n",
    "                            \"output_token_details\": {},\n",
    "                        },\n",
    "                    ),\n",
    "                    HumanMessage(\n",
    "                        content=\"Where did Peter Obi study?\",\n",
    "                        additional_kwargs={},\n",
    "                        response_metadata={},\n",
    "                    ),\n",
    "                ]\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "    \"run_id\": \"00f6ab86-4e41-49f9-b407-b7f868de6366\",\n",
    "    \"name\": \"ChatOpenAI\",\n",
    "    \"tags\": [\"seq:step:1\"],\n",
    "    \"metadata\": {\n",
    "        \"thread_id\": \"test-01\",\n",
    "        \"langgraph_step\": 13,\n",
    "        \"langgraph_node\": \"llm_call\",\n",
    "        \"langgraph_triggers\": (\"branch:to:llm_call\",),\n",
    "        \"langgraph_path\": (\"__pregel_pull\", \"llm_call\"),\n",
    "        \"langgraph_checkpoint_ns\": \"llm_call:55fed89a-cf89-f074-6731-48bd16c21ae9\",\n",
    "        \"checkpoint_ns\": \"llm_call:55fed89a-cf89-f074-6731-48bd16c21ae9\",\n",
    "        \"ls_provider\": \"openai\",\n",
    "        \"ls_model_name\": \"openai/gpt-oss-20b\",\n",
    "        \"ls_model_type\": \"chat\",\n",
    "        \"ls_temperature\": 0.0,\n",
    "        \"revision_id\": \"ae3dd81-dirty\",\n",
    "    },\n",
    "    \"parent_ids\": [\n",
    "        \"9c7cf01e-b92e-4d0c-88ab-25f0e77d9370\",\n",
    "        \"307e02fc-6562-4d85-822f-9d6ed1966ec1\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835245d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"event\": \"on_tool_end\",\n",
    "    \"data\": {\n",
    "        \"output\": {\n",
    "            \"query\": \"Peter Obi education where did he study\",\n",
    "            \"follow_up_questions\": None,\n",
    "            \"answer\": None,\n",
    "            \"images\": [],\n",
    "            \"results\": [\n",
    "                {\n",
    "                    \"url\": \"https://simple.wikipedia.org/wiki/Peter_Obi\",\n",
    "                    \"title\": \"Peter Obi - Simple English Wikipedia, the free encyclopedia\",\n",
    "                    \"content\": \"He had his tertiary education at the University of Nigeria in 1984 after his secondary education at Christ the King College, Onitsha.\",\n",
    "                    \"score\": 0.8827621,\n",
    "                    \"raw_content\": None,\n",
    "                },\n",
    "                {\n",
    "                    \"url\": \"https://kids.kiddle.co/Peter_Obi\",\n",
    "                    \"title\": \"Peter Obi for Kids\",\n",
    "                    \"content\": \"In 1980, he started studying Philosophy at the University of Nigeria in Nsukka. He graduated in 1984. Peter Obi also studied at several other\",\n",
    "                    \"score\": 0.86108357,\n",
    "                    \"raw_content\": None,\n",
    "                },\n",
    "                {\n",
    "                    \"url\": \"https://www.legit.ng/politics/1670240-peter-obis-educational-background-confirmed-details-show-schooled/\",\n",
    "                    \"title\": \"Peter Obi's Educational Background: Details Show His Certifications\",\n",
    "                    \"content\": \"He attended Lagos Business School, where he completed the Chief Executive Program, and later enrolled at Harvard Business School, completing two\",\n",
    "                    \"score\": 0.8138313,\n",
    "                    \"raw_content\": None,\n",
    "                },\n",
    "            ],\n",
    "            \"response_time\": 0.89,\n",
    "            \"request_id\": \"857f10aa-8815-4789-b120-c59ead398ceb\",\n",
    "        },\n",
    "        \"input\": {\"query\": \"Peter Obi education where did he study\"},\n",
    "    },\n",
    "    \"run_id\": \"e47fd9bf-2d37-4f5c-9369-ed62f47ba233\",\n",
    "    \"name\": \"tavily_search\",\n",
    "    \"tags\": [],\n",
    "    \"metadata\": {\n",
    "        \"thread_id\": \"test-01\",\n",
    "        \"langgraph_step\": 14,\n",
    "        \"langgraph_node\": \"tools\",\n",
    "        \"langgraph_triggers\": (\"branch:to:tools\",),\n",
    "        \"langgraph_path\": (\"__pregel_pull\", \"tools\"),\n",
    "        \"langgraph_checkpoint_ns\": \"tools:19aeca67-0f98-ffd1-d081-6405270c8188\",\n",
    "        \"checkpoint_ns\": \"tools:19aeca67-0f98-ffd1-d081-6405270c8188\",\n",
    "        \"revision_id\": \"ae3dd81-dirty\",\n",
    "    },\n",
    "    \"parent_ids\": [\n",
    "        \"9c7cf01e-b92e-4d0c-88ab-25f0e77d9370\",\n",
    "        \"212d580a-f36b-4d65-9489-209cb2ef0c2c\",\n",
    "        \"86bb7b58-1172-4af4-b8b1-e9f1af3b9251\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2aac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d50f95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35c47a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart-rag (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
